{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification is about to start ... \n",
      "=======================================================\n",
      "Dataset : npz/Z_RPI369.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "XGB_Classifying ...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.1s remaining:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.1s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.1s finished\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.603\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'max_depth': 6, 'max_leaf_nodes': 10, 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 30}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.547\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "XGBClassifier(max_depth=6, max_leaf_nodes=10, min_samples_leaf=8,\n",
      "              min_samples_split=20, n_estimators=30, probability=True)\n",
      "K_fold with 5 epoch : 0.5472972972972973\n",
      "[save_best_output]best_score_so_far : 0.6081081081081081\n",
      "=======================================================\n",
      "Dataset : npz/Z_RPI488.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "XGB_Classifying ...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.6s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.3s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.4s finished\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.859\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'max_depth': 6, 'max_leaf_nodes': 10, 'min_samples_leaf': 7, 'min_samples_split': 13, 'n_estimators': 125}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.878\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "XGBClassifier(max_depth=6, max_leaf_nodes=10, min_samples_leaf=7,\n",
      "              min_samples_split=13, n_estimators=125, probability=True)\n",
      "K_fold with 5 epoch : 0.8775510204081632\n",
      "[save_best_output]best_score_so_far : 0.8979591836734694\n",
      "=======================================================\n",
      "Dataset : npz/Z_RPI1807.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "XGB_Classifying ...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   15.2s remaining:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   15.2s remaining:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.4s finished\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.968\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'max_depth': 7, 'max_leaf_nodes': 30, 'min_samples_leaf': 18, 'min_samples_split': 6, 'n_estimators': 100}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.965\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "XGBClassifier(max_depth=7, max_leaf_nodes=30, min_samples_leaf=18,\n",
      "              min_samples_split=6, probability=True)\n",
      "K_fold with 5 epoch : 0.9645061728395061\n",
      "[save_best_output]best_score_so_far : 0.9722222222222222\n",
      "=======================================================\n",
      "Dataset : npz/Z_RPI2241.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "XGB_Classifying ...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.7s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.779\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'max_depth': 7, 'max_leaf_nodes': 30, 'min_samples_leaf': 6, 'min_samples_split': 13, 'n_estimators': 5}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.766\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "XGBClassifier(max_depth=7, max_leaf_nodes=30, min_samples_leaf=6,\n",
      "              min_samples_split=13, n_estimators=5, probability=True)\n",
      "K_fold with 5 epoch : 0.7658862876254181\n",
      "[save_best_output]best_score_so_far : 0.835005574136009\n",
      "=======================================================\n",
      "Dataset : npz/Z_NPInter.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "XGB_Classifying ...\n",
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.8min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cd1eceaa9671>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0mclassify_and_print_RPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1807\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[0mclassify_and_print_RPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2241\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mclassify_and_print_NPInter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-cd1eceaa9671>\u001b[0m in \u001b[0;36mclassify_and_print_NPInter\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclassify_and_print_NPInter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=======================================================\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[0mbest_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NPInter\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPARAM_GRID\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NPInter\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"RFC\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K_fold with {0} epoch : {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKFOLD_TIME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0msave_best_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NPInter\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cd1eceaa9671>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(npz_path, param_grid)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;31m#return Voting_Classifying(X, y, KFOLD_TIME)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;31m#return RF_Classifying(X, y, KFOLD_TIME, param_grid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mXGB_Classifying\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKFOLD_TIME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m     \u001b[1;31m#return LGBM_Classifying(X, y, KFOLD_TIME, param_grid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cd1eceaa9671>\u001b[0m in \u001b[0;36mXGB_Classifying\u001b[1;34m(X, y, KFOLD_TIME, param_grid)\u001b[0m\n\u001b[0;32m    181\u001b[0m                          scoring=\"accuracy\", n_jobs=-1, verbose=10)\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mgsXGBC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgsXGBC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgsXGBC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\graduationPiece\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperparams import *\n",
    "from rawdata_preprocessing import *\n",
    "#from RandomForestClassifier import RF_Classifying\n",
    "#from SVMClassifier import SVM_Classifying\n",
    "\n",
    "import Bio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#from warnings import filterwarnings\n",
    "#filterwarnings('ignore')\n",
    "\n",
    "from Logger import *\n",
    "from save_best_output import save_best_output\n",
    "\n",
    "def Voting_Classifying(X, y, KFOLD_TIME) :\n",
    "    #GBC_best = GBC_Classifying(X, y, KFOLD_TIME)\n",
    "    #RFC_best = RF_Classifying(X, y, KFOLD_TIME)\n",
    "    #SVMC_best = SVM_Classifying(X, y, KFOLD_TIME)\n",
    "    #XGBC_best = XGB_Classifying(X, y, KFOLD_TIME)\n",
    "    RFC_best = RandomForestClassifier(random_state=2)\n",
    "    SVMC_best = SVC(probability=True, random_state=2)\n",
    "    GBC_best = GradientBoostingClassifier(random_state=2)\n",
    "    XGBC_best = XGBClassifier(probability=True, random_state=2)\n",
    "    ABC_best = AdaBoostClassifier(random_state = 2)\n",
    "    BC_best = BaggingClassifier(random_state = 2)\n",
    "    LGBM_best = LGBMClassifier(random_state = 2)\n",
    "    \n",
    "    VC = VotingClassifier(estimators=[\n",
    "        #('ada', ABC_best), \n",
    "        #                              ('bc', BC_best),\n",
    "        #                              ('lgbm', LGBM_best),\n",
    "                                      ('rfc', RFC_best), \n",
    "                                      ('svc', SVMC_best), \n",
    "                                      ('gbc', GBC_best), \n",
    "                                      ('xgb', XGBC_best)\n",
    "                                      ], \n",
    "                          voting='soft', n_jobs=-1, verbose=10)\n",
    "    param_range = [0.1, 1.0]\n",
    "    param_grid = {\n",
    "        'gbc__n_estimators' : [100], 'gbc__max_depth' : [6], 'gbc__min_samples_leaf': [3], 'gbc__min_samples_split' : [2], 'gbc__learning_rate' : [0.05],\n",
    "        'svc__kernel' : ['rbf'], 'svc__C' : [0.1], 'svc__gamma': [0.1], 'svc__random_state' : [2],\n",
    "        'xgb__kernel' : ['rbf'], 'xgb__C' : [0.1], 'xgb__num_iterations': [1000], 'xgb__gamma':[0.1], 'xgb__random_state' : [2], 'xgb__learning_rate' : [0.1], 'xgb__n_estimators' : [100], 'xgb__max_depth' : [100],\n",
    "        'rfc__n_estimators' : [30],'rfc__max_depth' : [6],'rfc__min_samples_leaf' : [8],'rfc__min_samples_split' : [20], 'rfc__max_leaf_nodes' : [10],\n",
    "        #'ada__base_estimator' : [RFC_best, SVMC_best], 'ada__n_estimators' : [10], 'ada__learning_rate' : [0.01],\n",
    "        #'bc__base_estimator' : [SVMC_best, GBC_best, XGBC_best, ABC_best], 'bc__n_estimators' : [10],\n",
    "        #'lgbm__n_estimators' : [10], 'lgbm__min_samples_leaf' : [3], 'lgbm__min_samples_split' : [2], 'lgbm__learning_rate' : [0.01]\n",
    "    }\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsVC = GridSearchCV(estimator=VC, param_grid=param_grid, cv=KFOLD_TIME, n_jobs = -1, verbose=10)\n",
    "\n",
    "    gsVC = gsVC.fit(X_train,y_train)\n",
    "    score = gsVC.score(X_test, y_test)\n",
    "    \n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsVC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsVC.best_params_))\n",
    "    logger.warning('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsVC.best_estimator_))\n",
    "    \n",
    "    return score, gsVC.best_params_, gsVC.best_estimator_\n",
    "\n",
    "\n",
    "def Bagging_Classifying(X, y, KFOLD_TIME) :\n",
    "    BC = BaggingClassifier()\n",
    "    \n",
    "\"\"\"\n",
    "def GBC_Classifying(X, y, KFOLD_TIME) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"GBC_Classifying ... \")\n",
    "    gbrt = GradientBoostingClassifier(random_state = 0)\n",
    "    '''\n",
    "    param_grid = {\n",
    "        'n_estimators' : [100, 200], \n",
    "        'max_depth' : [6,8,10,12], \n",
    "        'min_samples_leaf': [3,5,7,10], \n",
    "        'min_samples_split' : [2,3,5,10], \n",
    "        'learning_rate' : [0.05, 0.1, 0.2]\n",
    "    }\n",
    "    '''\n",
    "    param_grid = {'n_estimators' : [100], 'max_depth' : [6], 'min_samples_leaf': [3], 'min_samples_split' : [2], 'learning_rate' : [0.05]}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsGBRT = GridSearchCV(gbrt, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=6, verbose=2)\n",
    "    \n",
    "    '''\n",
    "    gsGBRT.fit(X_train, y_train)\n",
    "    score = gsGBRT.score(X_test, y_test)\n",
    "    print('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsGBRT.best_score_))\n",
    "    print('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsGBRT.best_params_))\n",
    "    print('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    print('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsGBRT.best_estimator_))\n",
    "    '''\n",
    "    return score, gsGBRT.best_params_, gsGBRT.best_estimator_\n",
    "\n",
    "def SVM_Classifying(X, y, KFOLD_TIME) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"SVM_Classifying ... \")\n",
    "    SVMC = SVC(probability=True)\n",
    "    param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    #param_range = [0.1, 1.0]\n",
    "    '''\n",
    "    param_grid = [\n",
    "        {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['poly'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['linear'], 'C' : param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['sigmoid'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] }\n",
    "    ]\n",
    "    '''\n",
    "    param_grid = [\n",
    "        {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] }  \n",
    "    ]\n",
    "\n",
    "    #['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsSVMC = GridSearchCV(SVMC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=6, verbose=2)\n",
    "\n",
    "\n",
    "    '''\n",
    "    gsSVMC.fit(X, y)\n",
    "    score = gsSVMC.score(X_test, y_test)\n",
    "\n",
    "    SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "    print(\"best score : {}\".format(gsSVMC.best_score_))\n",
    "    print(\"best parameters : {}\".format(gsSVMC.best_params_))\n",
    "    print(\"train set score : {}\".format(gsSVMC.score(X, y)))\n",
    "    '''\n",
    "    return score, gsSVMC.best_params_, gsSVMC.best_estimator_\n",
    "\"\"\"\n",
    "def XGB_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"XGB_Classifying ...\")\n",
    "    XGBC = XGBClassifier(probability=True)\n",
    "    param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    '''\n",
    "    param_grid = {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01, 0.05, 0.1, 0.15, 0.2], \n",
    "                  'n_estimators' : [100, 200, 400, 600], \n",
    "                  'max_depth' : [4,6,8,10,12] }\n",
    "    \n",
    "    param_grid = {'kernel' : ['rbf'], 'C' : param_range, 'gamma':[0.1], 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01], \n",
    "                  'n_estimators' : [100], \n",
    "                  'max_depth' : [4]}\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsXGBC = GridSearchCV(XGBC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsXGBC.fit(X_train, y_train)\n",
    "    score = gsXGBC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsXGBC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsXGBC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsXGBC.best_estimator_))\n",
    "    \n",
    "    return score, gsXGBC.best_params_, gsXGBC.best_estimator_\n",
    "\n",
    "def LGBM_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"LGBM_Classifying ...\")\n",
    "    LGBC = LGBMClassifier(random_state = 2)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsLGBM = GridSearchCV(LGBC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsLGBM.fit(X_train, y_train)\n",
    "    score = gsLGBM.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsLGBM.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsLGBM.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsLGBM.best_estimator_))\n",
    "    \n",
    "    return score, gsLGBM.best_params_, gsLGBM.best_estimator_\n",
    "\n",
    "def RF_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"RF_Classifying ... \")\n",
    "    RFC = RandomForestClassifier(random_state=2)\n",
    "\n",
    "    \n",
    "    param_grid = {'n_estimators' : [10],'max_depth' : [6],'min_samples_leaf' : [8],'min_samples_split' : [8], 'max_leaf_nodes' : [10]}\n",
    "\n",
    "    kfold = KFold(n_splits=KFOLD_TIME, shuffle=True, random_state=11)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    \n",
    "    gsRFC = GridSearchCV(RFC, param_grid = param_grid, cv=kfold,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsRFC.fit(X_train, y_train)\n",
    "    # X_train, y_train 을 0.8:0.2 이런식으로 나눠서 cv 시킨다는 뜻인듯 ?\n",
    "    \n",
    "    score = gsRFC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsRFC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsRFC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsRFC.best_estimator_))\n",
    "    \n",
    "    #return gsRFC\n",
    "    return score, gsRFC.best_params_, gsRFC.best_estimator_\n",
    "\n",
    "def LR_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"LogisticRegressionCV_Classifying ... \")\n",
    "    \n",
    "    LRC = LogisticRegressionCV(random_state = 2)\n",
    "    param_range = [0.01 ,0.1, 1, 10, 100]\n",
    "    param_grid = {'C' : param_range, 'gamma':[0.1], 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01], \n",
    "                  'n_estimators' : [100], \n",
    "                  'max_depth' : [4]}\n",
    "    gsLRC = GridSearchCV(LRC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsLRC.fit(X_train, y_train)\n",
    "    \n",
    "    score = gsLRC.score(X_test, y_test)\n",
    "    \n",
    "    \n",
    "    score = gsLRC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsLRC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsLRC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsLRC.best_estimator_))\n",
    "    return score, gsLRC.best_params_, gsLRC.best_estimator_\n",
    "\n",
    "KFOLD_TIME = 5\n",
    "cv=KFold(n_splits=3,random_state=5,shuffle=True)\n",
    "\n",
    "p_feature_names = ['A', 'AA', 'AAA', 'AAB', 'AAC', 'AAD', 'AAE', 'AAF', 'AAG', 'AB', 'ABA', 'ABB', 'ABC', 'ABD', 'ABE', 'ABF', 'ABG', 'AC', 'ACA', 'ACB', 'ACC', 'ACD', 'ACE', 'ACF', 'ACG', 'AD', 'ADA', 'ADB', 'ADC', 'ADD', 'ADE', 'ADF', 'ADG', 'AE', 'AEA', 'AEB', 'AEC', 'AED', 'AEE', 'AEF', 'AEG', 'AF', 'AFA', 'AFB', 'AFC', 'AFD', 'AFE', 'AFF', 'AFG', 'AG', 'AGA', 'AGB', 'AGC', 'AGD', 'AGE', 'AGF', 'AGG', 'B', 'BA', 'BAA', 'BAB', 'BAC', 'BAD', 'BAE', 'BAF', 'BAG', 'BB', 'BBA', 'BBB', 'BBC', 'BBD', 'BBE', 'BBF', 'BBG', 'BC', 'BCA', 'BCB', 'BCC', 'BCD', 'BCE', 'BCF', 'BCG', 'BD', 'BDA', 'BDB', 'BDC', 'BDD', 'BDE', 'BDF', 'BDG', 'BE', 'BEA', 'BEB', 'BEC', 'BED', 'BEE', 'BEF', 'BEG', 'BF', 'BFA', 'BFB', 'BFC', 'BFD', 'BFE', 'BFF', 'BFG', 'BG', 'BGA', 'BGB', 'BGC', 'BGD', 'BGE', 'BGF', 'BGG', 'C', 'CA', 'CAA', 'CAB', 'CAC', 'CAD', 'CAE', 'CAF', 'CAG', 'CB', 'CBA', 'CBB', 'CBC', 'CBD', 'CBE', 'CBF', 'CBG', 'CC', 'CCA', 'CCB', 'CCC', 'CCD', 'CCE', 'CCF', 'CCG', 'CD', 'CDA', 'CDB', 'CDC', 'CDD', 'CDE', 'CDF', 'CDG', 'CE', 'CEA', 'CEB', 'CEC', 'CED', 'CEE', 'CEF', 'CEG', 'CF', 'CFA', 'CFB', 'CFC', 'CFD', 'CFE', 'CFF', 'CFG', 'CG', 'CGA', 'CGB', 'CGC', 'CGD', 'CGE', 'CGF', 'CGG', 'D', 'DA', 'DAA', 'DAB', 'DAC', 'DAD', 'DAE', 'DAF', 'DAG', 'DB', 'DBA', 'DBB', 'DBC', 'DBD', 'DBE', 'DBF', 'DBG', 'DC', 'DCA', 'DCB', 'DCC', 'DCD', 'DCE', 'DCF', 'DCG', 'DD', 'DDA', 'DDB', 'DDC', 'DDD', 'DDE', 'DDF', 'DDG', 'DE', 'DEA', 'DEB', 'DEC', 'DED', 'DEE', 'DEF', 'DEG', 'DF', 'DFA', 'DFB', 'DFC', 'DFD', 'DFE', 'DFF', 'DFG', 'DG', 'DGA', 'DGB', 'DGC', 'DGD', 'DGE', 'DGF', 'DGG', 'E', 'EA', 'EAA', 'EAB', 'EAC', 'EAD', 'EAE', 'EAF', 'EAG', 'EB', 'EBA', 'EBB', 'EBC', 'EBD', 'EBE', 'EBF', 'EBG', 'EC', 'ECA', 'ECB', 'ECC', 'ECD', 'ECE', 'ECF', 'ECG', 'ED', 'EDA', 'EDB', 'EDC', 'EDD', 'EDE', 'EDF', 'EDG', 'EE', 'EEA', 'EEB', 'EEC', 'EED', 'EEE', 'EEF', 'EEG', 'EF', 'EFA', 'EFB', 'EFC', 'EFD', 'EFE', 'EFF', 'EFG', 'EG', 'EGA', 'EGB', 'EGC', 'EGD', 'EGE', 'EGF', 'EGG', 'F', 'FA', 'FAA', 'FAB', 'FAC', 'FAD', 'FAE', 'FAF', 'FAG', 'FB', 'FBA', 'FBB', 'FBC', 'FBD', 'FBE', 'FBF', 'FBG', 'FC', 'FCA', 'FCB', 'FCC', 'FCD', 'FCE', 'FCF', 'FCG', 'FD', 'FDA', 'FDB', 'FDC', 'FDD', 'FDE', 'FDF', 'FDG', 'FE', 'FEA', 'FEB', 'FEC', 'FED', 'FEE', 'FEF', 'FEG', 'FF', 'FFA', 'FFB', 'FFC', 'FFD', 'FFE', 'FFF', 'FFG', 'FG', 'FGA', 'FGB', 'FGC', 'FGD', 'FGE', 'FGF', 'FGG', 'G', 'GA', 'GAA', 'GAB', 'GAC', 'GAD', 'GAE', 'GAF', 'GAG', 'GB', 'GBA', 'GBB', 'GBC', 'GBD', 'GBE', 'GBF', 'GBG', 'GC', 'GCA', 'GCB', 'GCC', 'GCD', 'GCE', 'GCF', 'GCG', 'GD', 'GDA', 'GDB', 'GDC', 'GDD', 'GDE', 'GDF', 'GDG', 'GE', 'GEA', 'GEB', 'GEC', 'GED', 'GEE', 'GEF', 'GEG', 'GF', 'GFA', 'GFB', 'GFC', 'GFD', 'GFE', 'GFF', 'GFG', 'GG', 'GGA', 'GGB', 'GGC', 'GGD', 'GGE', 'GGF', 'GGG']\n",
    "r_feature_names = ['A', 'AA', 'AAA', 'AAAA', 'AAAC', 'AAAG', 'AAAU', 'AAC', 'AACA', 'AACC', 'AACG', 'AACU', 'AAG', 'AAGA', 'AAGC', 'AAGG', 'AAGU', 'AAU', 'AAUA', 'AAUC', 'AAUG', 'AAUU', 'AC', 'ACA', 'ACAA', 'ACAC', 'ACAG', 'ACAU', 'ACC', 'ACCA', 'ACCC', 'ACCG', 'ACCU', 'ACG', 'ACGA', 'ACGC', 'ACGG', 'ACGU', 'ACU', 'ACUA', 'ACUC', 'ACUG', 'ACUU', 'AG', 'AGA', 'AGAA', 'AGAC', 'AGAG', 'AGAU', 'AGC', 'AGCA', 'AGCC', 'AGCG', 'AGCU', 'AGG', 'AGGA', 'AGGC', 'AGGG', 'AGGU', 'AGU', 'AGUA', 'AGUC', 'AGUG', 'AGUU', 'AU', 'AUA', 'AUAA', 'AUAC', 'AUAG', 'AUAU', 'AUC', 'AUCA', 'AUCC', 'AUCG', 'AUCU', 'AUG', 'AUGA', 'AUGC', 'AUGG', 'AUGU', 'AUU', 'AUUA', 'AUUC', 'AUUG', 'AUUU', 'C', 'CA', 'CAA', 'CAAA', 'CAAC', 'CAAG', 'CAAU', 'CAC', 'CACA', 'CACC', 'CACG', 'CACU', 'CAG', 'CAGA', 'CAGC', 'CAGG', 'CAGU', 'CAU', 'CAUA', 'CAUC', 'CAUG', 'CAUU', 'CC', 'CCA', 'CCAA', 'CCAC', 'CCAG', 'CCAU', 'CCC', 'CCCA', 'CCCC', 'CCCG', 'CCCU', 'CCG', 'CCGA', 'CCGC', 'CCGG', 'CCGU', 'CCU', 'CCUA', 'CCUC', 'CCUG', 'CCUU', 'CG', 'CGA', 'CGAA', 'CGAC', 'CGAG', 'CGAU', 'CGC', 'CGCA', 'CGCC', 'CGCG', 'CGCU', 'CGG', 'CGGA', 'CGGC', 'CGGG', 'CGGU', 'CGU', 'CGUA', 'CGUC', 'CGUG', 'CGUU', 'CU', 'CUA', 'CUAA', 'CUAC', 'CUAG', 'CUAU', 'CUC', 'CUCA', 'CUCC', 'CUCG', 'CUCU', 'CUG', 'CUGA', 'CUGC', 'CUGG', 'CUGU', 'CUU', 'CUUA', 'CUUC', 'CUUG', 'CUUU', 'G', 'GA', 'GAA', 'GAAA', 'GAAC', 'GAAG', 'GAAU', 'GAC', 'GACA', 'GACC', 'GACG', 'GACU', 'GAG', 'GAGA', 'GAGC', 'GAGG', 'GAGU', 'GAU', 'GAUA', 'GAUC', 'GAUG', 'GAUU', 'GC', 'GCA', 'GCAA', 'GCAC', 'GCAG', 'GCAU', 'GCC', 'GCCA', 'GCCC', 'GCCG', 'GCCU', 'GCG', 'GCGA', 'GCGC', 'GCGG', 'GCGU', 'GCU', 'GCUA', 'GCUC', 'GCUG', 'GCUU', 'GG', 'GGA', 'GGAA', 'GGAC', 'GGAG', 'GGAU', 'GGC', 'GGCA', 'GGCC', 'GGCG', 'GGCU', 'GGG', 'GGGA', 'GGGC', 'GGGG', 'GGGU', 'GGU', 'GGUA', 'GGUC', 'GGUG', 'GGUU', 'GU', 'GUA', 'GUAA', 'GUAC', 'GUAG', 'GUAU', 'GUC', 'GUCA', 'GUCC', 'GUCG', 'GUCU', 'GUG', 'GUGA', 'GUGC', 'GUGG', 'GUGU', 'GUU', 'GUUA', 'GUUC', 'GUUG', 'GUUU', 'U', 'UA', 'UAA', 'UAAA', 'UAAC', 'UAAG', 'UAAU', 'UAC', 'UACA', 'UACC', 'UACG', 'UACU', 'UAG', 'UAGA', 'UAGC', 'UAGG', 'UAGU', 'UAU', 'UAUA', 'UAUC', 'UAUG', 'UAUU', 'UC', 'UCA', 'UCAA', 'UCAC', 'UCAG', 'UCAU', 'UCC', 'UCCA', 'UCCC', 'UCCG', 'UCCU', 'UCG', 'UCGA', 'UCGC', 'UCGG', 'UCGU', 'UCU', 'UCUA', 'UCUC', 'UCUG', 'UCUU', 'UG', 'UGA', 'UGAA', 'UGAC', 'UGAG', 'UGAU', 'UGC', 'UGCA', 'UGCC', 'UGCG', 'UGCU', 'UGG', 'UGGA', 'UGGC', 'UGGG', 'UGGU', 'UGU', 'UGUA', 'UGUC', 'UGUG', 'UGUU', 'UU', 'UUA', 'UUAA', 'UUAC', 'UUAG', 'UUAU', 'UUC', 'UUCA', 'UUCC', 'UUCG', 'UUCU', 'UUG', 'UUGA', 'UUGC', 'UUGG', 'UUGU', 'UUU', 'UUUA', 'UUUC', 'UUUG', 'UUUU']\n",
    "xgb_r_feature_names = ['r_A', 'r_AA', 'r_AAA', 'r_AAAA', 'r_AAAC', 'r_AAAG', 'r_AAAU', 'r_AAC', 'r_AACA', 'r_AACC', 'r_AACG', 'r_AACU', 'r_AAG', 'r_AAGA', 'r_AAGC', 'r_AAGG', 'r_AAGU', 'r_AAU', 'r_AAUA', 'r_AAUC', 'r_AAUG', 'r_AAUU', 'r_AC', 'r_ACA', 'r_ACAA', 'r_ACAC', 'r_ACAG', 'r_ACAU', 'r_ACC', 'r_ACCA', 'r_ACCC', 'r_ACCG', 'r_ACCU', 'r_ACG', 'r_ACGA', 'r_ACGC', 'r_ACGG', 'r_ACGU', 'r_ACU', 'r_ACUA', 'r_ACUC', 'r_ACUG', 'r_ACUU', 'r_AG', 'r_AGA', 'r_AGAA', 'r_AGAC', 'r_AGAG', 'r_AGAU', 'r_AGC', 'r_AGCA', 'r_AGCC', 'r_AGCG', 'r_AGCU', 'r_AGG', 'r_AGGA', 'r_AGGC', 'r_AGGG', 'r_AGGU', 'r_AGU', 'r_AGUA', 'r_AGUC', 'r_AGUG', 'r_AGUU', 'r_AU', 'r_AUA', 'r_AUAA', 'r_AUAC', 'r_AUAG', 'r_AUAU', 'r_AUC', 'r_AUCA', 'r_AUCC', 'r_AUCG', 'r_AUCU', 'r_AUG', 'r_AUGA', 'r_AUGC', 'r_AUGG', 'r_AUGU', 'r_AUU', 'r_AUUA', 'r_AUUC', 'r_AUUG', 'r_AUUU', 'r_C', 'r_CA', 'r_CAA', 'r_CAAA', 'r_CAAC', 'r_CAAG', 'r_CAAU', 'r_CAC', 'r_CACA', 'r_CACC', 'r_CACG', 'r_CACU', 'r_CAG', 'r_CAGA', 'r_CAGC', 'r_CAGG', 'r_CAGU', 'r_CAU', 'r_CAUA', 'r_CAUC', 'r_CAUG', 'r_CAUU', 'r_CC', 'r_CCA', 'r_CCAA', 'r_CCAC', 'r_CCAG', 'r_CCAU', 'r_CCC', 'r_CCCA', 'r_CCCC', 'r_CCCG', 'r_CCCU', 'r_CCG', 'r_CCGA', 'r_CCGC', 'r_CCGG', 'r_CCGU', 'r_CCU', 'r_CCUA', 'r_CCUC', 'r_CCUG', 'r_CCUU', 'r_CG', 'r_CGA', 'r_CGAA', 'r_CGAC', 'r_CGAG', 'r_CGAU', 'r_CGC', 'r_CGCA', 'r_CGCC', 'r_CGCG', 'r_CGCU', 'r_CGG', 'r_CGGA', 'r_CGGC', 'r_CGGG', 'r_CGGU', 'r_CGU', 'r_CGUA', 'r_CGUC', 'r_CGUG', 'r_CGUU', 'r_CU', 'r_CUA', 'r_CUAA', 'r_CUAC', 'r_CUAG', 'r_CUAU', 'r_CUC', 'r_CUCA', 'r_CUCC', 'r_CUCG', 'r_CUCU', 'r_CUG', 'r_CUGA', 'r_CUGC', 'r_CUGG', 'r_CUGU', 'r_CUU', 'r_CUUA', 'r_CUUC', 'r_CUUG', 'r_CUUU', 'r_G', 'r_GA', 'r_GAA', 'r_GAAA', 'r_GAAC', 'r_GAAG', 'r_GAAU', 'r_GAC', 'r_GACA', 'r_GACC', 'r_GACG', 'r_GACU', 'r_GAG', 'r_GAGA', 'r_GAGC', 'r_GAGG', 'r_GAGU', 'r_GAU', 'r_GAUA', 'r_GAUC', 'r_GAUG', 'r_GAUU', 'r_GC', 'r_GCA', 'r_GCAA', 'r_GCAC', 'r_GCAG', 'r_GCAU', 'r_GCC', 'r_GCCA', 'r_GCCC', 'r_GCCG', 'r_GCCU', 'r_GCG', 'r_GCGA', 'r_GCGC', 'r_GCGG', 'r_GCGU', 'r_GCU', 'r_GCUA', 'r_GCUC', 'r_GCUG', 'r_GCUU', 'r_GG', 'r_GGA', 'r_GGAA', 'r_GGAC', 'r_GGAG', 'r_GGAU', 'r_GGC', 'r_GGCA', 'r_GGCC', 'r_GGCG', 'r_GGCU', 'r_GGG', 'r_GGGA', 'r_GGGC', 'r_GGGG', 'r_GGGU', 'r_GGU', 'r_GGUA', 'r_GGUC', 'r_GGUG', 'r_GGUU', 'r_GU', 'r_GUA', 'r_GUAA', 'r_GUAC', 'r_GUAG', 'r_GUAU', 'r_GUC', 'r_GUCA', 'r_GUCC', 'r_GUCG', 'r_GUCU', 'r_GUG', 'r_GUGA', 'r_GUGC', 'r_GUGG', 'r_GUGU', 'r_GUU', 'r_GUUA', 'r_GUUC', 'r_GUUG', 'r_GUUU', 'r_U', 'r_UA', 'r_UAA', 'r_UAAA', 'r_UAAC', 'r_UAAG', 'r_UAAU', 'r_UAC', 'r_UACA', 'r_UACC', 'r_UACG', 'r_UACU', 'r_UAG', 'r_UAGA', 'r_UAGC', 'r_UAGG', 'r_UAGU', 'r_UAU', 'r_UAUA', 'r_UAUC', 'r_UAUG', 'r_UAUU', 'r_UC', 'r_UCA', 'r_UCAA', 'r_UCAC', 'r_UCAG', 'r_UCAU', 'r_UCC', 'r_UCCA', 'r_UCCC', 'r_UCCG', 'r_UCCU', 'r_UCG', 'r_UCGA', 'r_UCGC', 'r_UCGG', 'r_UCGU', 'r_UCU', 'r_UCUA', 'r_UCUC', 'r_UCUG', 'r_UCUU', 'r_UG', 'r_UGA', 'r_UGAA', 'r_UGAC', 'r_UGAG', 'r_UGAU', 'r_UGC', 'r_UGCA', 'r_UGCC', 'r_UGCG', 'r_UGCU', 'r_UGG', 'r_UGGA', 'r_UGGC', 'r_UGGG', 'r_UGGU', 'r_UGU', 'r_UGUA', 'r_UGUC', 'r_UGUG', 'r_UGUU', 'r_UU', 'r_UUA', 'r_UUAA', 'r_UUAC', 'r_UUAG', 'r_UUAU', 'r_UUC', 'r_UUCA', 'r_UUCC', 'r_UUCG', 'r_UUCU', 'r_UUG', 'r_UUGA', 'r_UUGC', 'r_UUGG', 'r_UUGU', 'r_UUU', 'r_UUUA', 'r_UUUC', 'r_UUUG', 'r_UUUU']\n",
    "\n",
    "train_combined_arr = []\n",
    "val_combined_arr = []\n",
    "\n",
    "def classify(npz_path, param_grid) :\n",
    "    logger.debug(\"Dataset : {}\".format(npz_path))\n",
    "    mydata = np.load(npz_path)\n",
    "    XP = mydata['XP']\n",
    "    XR = mydata['XR']\n",
    "    Y = mydata['Y']\n",
    "\n",
    "    #combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_feature_names + r_feature_names + ['target'])\n",
    "    combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_feature_names + xgb_r_feature_names + ['target'])\n",
    "\n",
    "\n",
    "    features = list(combined_pd.columns[:-1])\n",
    "    X = combined_pd[features]\n",
    "    y = combined_pd['target']\n",
    "\n",
    "    #return Voting_Classifying(X, y, KFOLD_TIME)\n",
    "    #return RF_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "    return XGB_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "    #return LGBM_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "\n",
    "def classify_and_print_NPInter(dataset):\n",
    "    logger.debug(\"=======================================================\")\n",
    "    best_score, best_params, best_model = classify(dataset[\"NPInter\"], PARAM_GRID[\"NPInter\"][\"RFC\"])\n",
    "    logger.warning(\"K_fold with {0} epoch : {1}\".format(KFOLD_TIME, best_score))\n",
    "    save_best_output(dataset[\"NPInter\"], best_score, best_params, str(best_model).replace('\\n', ''))\n",
    "    \n",
    "def classify_and_print_RPI(size, dataset):\n",
    "    logger.debug(\"=======================================================\")\n",
    "    best_score, best_params, best_model = classify(dataset[\"RPI\"][size], PARAM_GRID[\"RPI\"][size][\"RFC\"])\n",
    "    logger.warning(\"K_fold with {0} epoch : {1}\".format(KFOLD_TIME, best_score))\n",
    "\n",
    "    save_best_output(dataset[\"RPI\"][size], best_score, best_params, str(best_model).replace('\\n', ''))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = Z_NPZ_PATH\n",
    "    logger.debug(\"Classification is about to start ... \")\n",
    "    classify_and_print_RPI(369, dataset)\n",
    "    classify_and_print_RPI(488, dataset)\n",
    "    classify_and_print_RPI(1807, dataset)\n",
    "    classify_and_print_RPI(2241, dataset)\n",
    "    classify_and_print_NPInter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:graduationPiece] *",
   "language": "python",
   "name": "conda-env-graduationPiece-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
