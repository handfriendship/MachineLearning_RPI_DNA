{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification is about to start ... \n",
      "=======================================================\n",
      "Dataset : npz/Z_RPI369.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.1min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.1min remaining:   44.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.1min finished\n",
      "len : 148 - y_test : [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0.] - y_test[:, 1] : \n",
      "len : 148 - y_test_predict : [[0.63927307 0.36072693]\n",
      " [0.62432699 0.37567301]\n",
      " [0.60001089 0.39998912]\n",
      " [0.56712291 0.43287709]\n",
      " [0.33984162 0.66015838]\n",
      " [0.29686166 0.70313834]\n",
      " [0.52972471 0.47027529]\n",
      " [0.62481763 0.37518237]\n",
      " [0.51357995 0.48642005]\n",
      " [0.42464036 0.57535963]\n",
      " [0.28702885 0.71297115]\n",
      " [0.68193444 0.31806556]\n",
      " [0.65455574 0.34544426]\n",
      " [0.58911467 0.41088534]\n",
      " [0.65425219 0.34574782]\n",
      " [0.64414161 0.35585839]\n",
      " [0.55433563 0.44566437]\n",
      " [0.68168201 0.318318  ]\n",
      " [0.29880066 0.70119934]\n",
      " [0.52821819 0.4717818 ]\n",
      " [0.22758547 0.77241453]\n",
      " [0.53711508 0.46288492]\n",
      " [0.64525171 0.35474829]\n",
      " [0.35269732 0.64730268]\n",
      " [0.41448153 0.58551847]\n",
      " [0.32594956 0.67405044]\n",
      " [0.65058444 0.34941556]\n",
      " [0.43052879 0.5694712 ]\n",
      " [0.23005348 0.76994652]\n",
      " [0.38041073 0.61958927]\n",
      " [0.49608974 0.50391026]\n",
      " [0.39109126 0.60890874]\n",
      " [0.63596937 0.36403064]\n",
      " [0.65991925 0.34008075]\n",
      " [0.32073556 0.67926444]\n",
      " [0.38363226 0.61636774]\n",
      " [0.34528945 0.65471055]\n",
      " [0.68852241 0.31147759]\n",
      " [0.54956002 0.45043998]\n",
      " [0.58083801 0.419162  ]\n",
      " [0.55411288 0.44588711]\n",
      " [0.58165694 0.41834306]\n",
      " [0.49872554 0.50127446]\n",
      " [0.69646171 0.30353829]\n",
      " [0.64753295 0.35246704]\n",
      " [0.72173019 0.27826982]\n",
      " [0.48138921 0.5186108 ]\n",
      " [0.54761473 0.45238527]\n",
      " [0.64970358 0.35029642]\n",
      " [0.70219124 0.29780876]\n",
      " [0.5805113  0.41948871]\n",
      " [0.43491494 0.56508506]\n",
      " [0.58683593 0.41316407]\n",
      " [0.3365165  0.6634835 ]\n",
      " [0.42518266 0.57481734]\n",
      " [0.54965878 0.45034122]\n",
      " [0.4711467  0.5288533 ]\n",
      " [0.55205776 0.44794225]\n",
      " [0.25944387 0.74055613]\n",
      " [0.37222013 0.62777987]\n",
      " [0.60001089 0.39998912]\n",
      " [0.27168411 0.72831589]\n",
      " [0.45417694 0.54582306]\n",
      " [0.37410588 0.62589412]\n",
      " [0.31368757 0.68631243]\n",
      " [0.50921448 0.49078552]\n",
      " [0.30415828 0.69584172]\n",
      " [0.35185367 0.64814633]\n",
      " [0.64119535 0.35880465]\n",
      " [0.41898796 0.58101204]\n",
      " [0.29720783 0.70279217]\n",
      " [0.55731259 0.44268741]\n",
      " [0.70216012 0.29783988]\n",
      " [0.32126034 0.67873966]\n",
      " [0.51841581 0.48158418]\n",
      " [0.7235075  0.2764925 ]\n",
      " [0.40358586 0.59641414]\n",
      " [0.51316399 0.48683601]\n",
      " [0.30750931 0.69249069]\n",
      " [0.70079466 0.29920533]\n",
      " [0.54246256 0.45753744]\n",
      " [0.71716109 0.28283892]\n",
      " [0.46548715 0.53451285]\n",
      " [0.22183339 0.77816661]\n",
      " [0.29202225 0.70797775]\n",
      " [0.35920056 0.64079944]\n",
      " [0.5670923  0.4329077 ]\n",
      " [0.60453231 0.39546768]\n",
      " [0.67494381 0.32505619]\n",
      " [0.74746121 0.25253878]\n",
      " [0.2827348  0.7172652 ]\n",
      " [0.46737094 0.53262906]\n",
      " [0.43676307 0.56323693]\n",
      " [0.73384398 0.26615601]\n",
      " [0.46605287 0.53394713]\n",
      " [0.58475319 0.41524681]\n",
      " [0.58092337 0.41907663]\n",
      " [0.52500092 0.47499909]\n",
      " [0.71228426 0.28771574]\n",
      " [0.44713787 0.55286213]\n",
      " [0.39759868 0.60240132]\n",
      " [0.34258239 0.65741761]\n",
      " [0.5828198  0.41718021]\n",
      " [0.2956618  0.7043382 ]\n",
      " [0.53426391 0.46573608]\n",
      " [0.49664445 0.50335555]\n",
      " [0.2734858  0.7265142 ]\n",
      " [0.50560793 0.49439207]\n",
      " [0.62158206 0.37841795]\n",
      " [0.32077683 0.67922317]\n",
      " [0.31858827 0.68141173]\n",
      " [0.56877467 0.43122533]\n",
      " [0.36321172 0.63678828]\n",
      " [0.34088468 0.65911532]\n",
      " [0.39271224 0.60728776]\n",
      " [0.68388806 0.31611195]\n",
      " [0.26087829 0.73912171]\n",
      " [0.64057642 0.35942358]\n",
      " [0.25955905 0.74044095]\n",
      " [0.2784493  0.7215507 ]\n",
      " [0.54798175 0.45201825]\n",
      " [0.71197258 0.28802743]\n",
      " [0.26228209 0.73771791]\n",
      " [0.2784493  0.7215507 ]\n",
      " [0.25172801 0.74827199]\n",
      " [0.55154598 0.44845402]\n",
      " [0.25616694 0.74383306]\n",
      " [0.31872116 0.68127884]\n",
      " [0.70116634 0.29883367]\n",
      " [0.74324187 0.25675814]\n",
      " [0.44702015 0.55297985]\n",
      " [0.34948996 0.65051004]\n",
      " [0.49555997 0.50444003]\n",
      " [0.49009642 0.50990358]\n",
      " [0.58740653 0.41259346]\n",
      " [0.3213619  0.6786381 ]\n",
      " [0.44574334 0.55425666]\n",
      " [0.53338136 0.46661863]\n",
      " [0.69303293 0.30696708]\n",
      " [0.32090675 0.67909325]\n",
      " [0.55761747 0.44238252]\n",
      " [0.39918312 0.60081688]\n",
      " [0.34304021 0.65695979]\n",
      " [0.5845829  0.4154171 ]\n",
      " [0.29989349 0.70010651]\n",
      " [0.27940352 0.72059648]\n",
      " [0.32957295 0.67042705]\n",
      " [0.47176049 0.52823951]] - y_test_predict[:, 1] : [0.36072693 0.37567301 0.39998912 0.43287709 0.66015838 0.70313834\n",
      " 0.47027529 0.37518237 0.48642005 0.57535963 0.71297115 0.31806556\n",
      " 0.34544426 0.41088534 0.34574782 0.35585839 0.44566437 0.318318\n",
      " 0.70119934 0.4717818  0.77241453 0.46288492 0.35474829 0.64730268\n",
      " 0.58551847 0.67405044 0.34941556 0.5694712  0.76994652 0.61958927\n",
      " 0.50391026 0.60890874 0.36403064 0.34008075 0.67926444 0.61636774\n",
      " 0.65471055 0.31147759 0.45043998 0.419162   0.44588711 0.41834306\n",
      " 0.50127446 0.30353829 0.35246704 0.27826982 0.5186108  0.45238527\n",
      " 0.35029642 0.29780876 0.41948871 0.56508506 0.41316407 0.6634835\n",
      " 0.57481734 0.45034122 0.5288533  0.44794225 0.74055613 0.62777987\n",
      " 0.39998912 0.72831589 0.54582306 0.62589412 0.68631243 0.49078552\n",
      " 0.69584172 0.64814633 0.35880465 0.58101204 0.70279217 0.44268741\n",
      " 0.29783988 0.67873966 0.48158418 0.2764925  0.59641414 0.48683601\n",
      " 0.69249069 0.29920533 0.45753744 0.28283892 0.53451285 0.77816661\n",
      " 0.70797775 0.64079944 0.4329077  0.39546768 0.32505619 0.25253878\n",
      " 0.7172652  0.53262906 0.56323693 0.26615601 0.53394713 0.41524681\n",
      " 0.41907663 0.47499909 0.28771574 0.55286213 0.60240132 0.65741761\n",
      " 0.41718021 0.7043382  0.46573608 0.50335555 0.7265142  0.49439207\n",
      " 0.37841795 0.67922317 0.68141173 0.43122533 0.63678828 0.65911532\n",
      " 0.60728776 0.31611195 0.73912171 0.35942358 0.74044095 0.7215507\n",
      " 0.45201825 0.28802743 0.73771791 0.7215507  0.74827199 0.44845402\n",
      " 0.74383306 0.68127884 0.29883367 0.25675814 0.55297985 0.65051004\n",
      " 0.50444003 0.50990358 0.41259346 0.6786381  0.55425666 0.46661863\n",
      " 0.30696708 0.67909325 0.44238252 0.60081688 0.65695979 0.4154171\n",
      " 0.70010651 0.72059648 0.67042705 0.52823951]\n",
      "{'Voting-Classifier': array([0.60810811, 0.62857143, 0.58974359, 0.57894737, 0.21807551,\n",
      "       0.68498168])}\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.581\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'gbc__learning_rate': 0.05, 'gbc__max_depth': 6, 'gbc__min_samples_leaf': 3, 'gbc__min_samples_split': 2, 'gbc__n_estimators': 100, 'rfc__max_depth': 6, 'rfc__max_leaf_nodes': 10, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 30, 'svc__C': 0.1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 2, 'xgb__C': 0.1, 'xgb__gamma': 0.1, 'xgb__kernel': 'rbf', 'xgb__learning_rate': 0.1, 'xgb__max_depth': 100, 'xgb__n_estimators': 100, 'xgb__num_iterations': 1000, 'xgb__random_state': 2}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.608\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "VotingClassifier(estimators=[('rfc',\n",
      "                              RandomForestClassifier(max_depth=6,\n",
      "                                                     max_leaf_nodes=10,\n",
      "                                                     min_samples_leaf=8,\n",
      "                                                     min_samples_split=20,\n",
      "                                                     n_estimators=30,\n",
      "                                                     random_state=2)),\n",
      "                             ('svc',\n",
      "                              SVC(C=0.1, gamma=0.1, probability=True,\n",
      "                                  random_state=2)),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(learning_rate=0.05,\n",
      "                                                         max_depth=6,\n",
      "                                                         min_samples_leaf=3,\n",
      "                                                         random_state=2)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(C=0.1, gamma=0.1, kernel='rbf',\n",
      "                                            max_depth=100, num_iterations=1000,\n",
      "                                            probability=True,\n",
      "                                            random_state=2))],\n",
      "                 n_jobs=-1, verbose=10, voting='soft')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K_fold with 5 epoch : 0.6081081081081081\n",
      "[save_best_output]best_score_so_far : 0.6081081081081081\n",
      "=======================================================\n",
      "Dataset : npz/Z_RPI488.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   16.8s remaining:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   17.0s remaining:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   17.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   17.5s finished\n",
      "len : 98 - y_test : [1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1.] - y_test[:, 1] : \n",
      "len : 98 - y_test_predict : [[0.13008367 0.86991633]\n",
      " [0.84491632 0.15508369]\n",
      " [0.49069182 0.50930818]\n",
      " [0.13278373 0.86721627]\n",
      " [0.78473597 0.21526402]\n",
      " [0.67522148 0.32477851]\n",
      " [0.13001855 0.86998145]\n",
      " [0.82707932 0.17292067]\n",
      " [0.20801111 0.79198889]\n",
      " [0.24197218 0.75802782]\n",
      " [0.12560822 0.87439178]\n",
      " [0.12754883 0.87245117]\n",
      " [0.82408818 0.17591181]\n",
      " [0.12861981 0.87138019]\n",
      " [0.61864732 0.38135268]\n",
      " [0.81126603 0.18873396]\n",
      " [0.84972034 0.15027967]\n",
      " [0.13322517 0.86677483]\n",
      " [0.85416006 0.14583994]\n",
      " [0.84373388 0.15626612]\n",
      " [0.12768914 0.87231086]\n",
      " [0.26140578 0.73859422]\n",
      " [0.82200168 0.17799832]\n",
      " [0.83336023 0.16663977]\n",
      " [0.81627417 0.18372583]\n",
      " [0.12804811 0.87195189]\n",
      " [0.14624562 0.85375438]\n",
      " [0.1427612  0.8572388 ]\n",
      " [0.8105339  0.18946609]\n",
      " [0.85234854 0.14765146]\n",
      " [0.83554907 0.16445094]\n",
      " [0.84569896 0.15430103]\n",
      " [0.71197244 0.28802756]\n",
      " [0.36203527 0.63796473]\n",
      " [0.80306839 0.19693161]\n",
      " [0.84614419 0.15385581]\n",
      " [0.15944994 0.84055006]\n",
      " [0.13063125 0.86936875]\n",
      " [0.83106467 0.16893534]\n",
      " [0.73160785 0.26839215]\n",
      " [0.81652011 0.18347988]\n",
      " [0.13933303 0.86066697]\n",
      " [0.13253725 0.86746275]\n",
      " [0.20974377 0.79025623]\n",
      " [0.13365612 0.86634388]\n",
      " [0.78369026 0.21630974]\n",
      " [0.12687056 0.87312944]\n",
      " [0.72436544 0.27563457]\n",
      " [0.13010368 0.86989632]\n",
      " [0.13449405 0.86550595]\n",
      " [0.79379078 0.20620922]\n",
      " [0.83659807 0.16340194]\n",
      " [0.74203621 0.25796379]\n",
      " [0.75082357 0.24917643]\n",
      " [0.84209079 0.1579092 ]\n",
      " [0.14795839 0.85204161]\n",
      " [0.85010045 0.14989955]\n",
      " [0.82970012 0.17029988]\n",
      " [0.13383346 0.86616654]\n",
      " [0.12603025 0.87396975]\n",
      " [0.80009285 0.19990715]\n",
      " [0.85235232 0.14764767]\n",
      " [0.8528821  0.1471179 ]\n",
      " [0.85071953 0.14928048]\n",
      " [0.71369503 0.28630497]\n",
      " [0.8344719  0.1655281 ]\n",
      " [0.12693461 0.87306539]\n",
      " [0.13330299 0.86669701]\n",
      " [0.77556702 0.22443299]\n",
      " [0.1386583  0.8613417 ]\n",
      " [0.83536204 0.16463797]\n",
      " [0.82855872 0.17144127]\n",
      " [0.82644545 0.17355454]\n",
      " [0.12909799 0.87090201]\n",
      " [0.80800252 0.19199747]\n",
      " [0.12853815 0.87146185]\n",
      " [0.12587137 0.87412863]\n",
      " [0.21240053 0.78759947]\n",
      " [0.83034356 0.16965644]\n",
      " [0.83279734 0.16720267]\n",
      " [0.64591409 0.3540859 ]\n",
      " [0.85372893 0.14627106]\n",
      " [0.80788848 0.19211151]\n",
      " [0.13604253 0.86395747]\n",
      " [0.16738737 0.83261263]\n",
      " [0.22013824 0.77986176]\n",
      " [0.13134499 0.86865501]\n",
      " [0.12910149 0.87089851]\n",
      " [0.12515753 0.87484247]\n",
      " [0.84740255 0.15259746]\n",
      " [0.83820162 0.16179838]\n",
      " [0.85132466 0.14867534]\n",
      " [0.79095317 0.20904683]\n",
      " [0.69106823 0.30893176]\n",
      " [0.13475138 0.86524862]\n",
      " [0.81138683 0.18861317]\n",
      " [0.8390968  0.16090319]\n",
      " [0.24989932 0.75010068]] - y_test_predict[:, 1] : [0.86991633 0.15508369 0.50930818 0.86721627 0.21526402 0.32477851\n",
      " 0.86998145 0.17292067 0.79198889 0.75802782 0.87439178 0.87245117\n",
      " 0.17591181 0.87138019 0.38135268 0.18873396 0.15027967 0.86677483\n",
      " 0.14583994 0.15626612 0.87231086 0.73859422 0.17799832 0.16663977\n",
      " 0.18372583 0.87195189 0.85375438 0.8572388  0.18946609 0.14765146\n",
      " 0.16445094 0.15430103 0.28802756 0.63796473 0.19693161 0.15385581\n",
      " 0.84055006 0.86936875 0.16893534 0.26839215 0.18347988 0.86066697\n",
      " 0.86746275 0.79025623 0.86634388 0.21630974 0.87312944 0.27563457\n",
      " 0.86989632 0.86550595 0.20620922 0.16340194 0.25796379 0.24917643\n",
      " 0.1579092  0.85204161 0.14989955 0.17029988 0.86616654 0.87396975\n",
      " 0.19990715 0.14764767 0.1471179  0.14928048 0.28630497 0.1655281\n",
      " 0.87306539 0.86669701 0.22443299 0.8613417  0.16463797 0.17144127\n",
      " 0.17355454 0.87090201 0.19199747 0.87146185 0.87412863 0.78759947\n",
      " 0.16965644 0.16720267 0.3540859  0.14627106 0.19211151 0.86395747\n",
      " 0.83261263 0.77986176 0.86865501 0.87089851 0.87484247 0.15259746\n",
      " 0.16179838 0.14867534 0.20904683 0.30893176 0.86524862 0.18861317\n",
      " 0.16090319 0.75010068]\n",
      "{'Voting-Classifier': array([0.86734694, 0.8       , 0.9375    , 0.93023256, 0.74293715,\n",
      "       0.93166667])}\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.877\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'gbc__learning_rate': 0.05, 'gbc__max_depth': 6, 'gbc__min_samples_leaf': 3, 'gbc__min_samples_split': 2, 'gbc__n_estimators': 100, 'rfc__max_depth': 6, 'rfc__max_leaf_nodes': 10, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 30, 'svc__C': 0.1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 2, 'xgb__C': 0.1, 'xgb__gamma': 0.1, 'xgb__kernel': 'rbf', 'xgb__learning_rate': 0.1, 'xgb__max_depth': 100, 'xgb__n_estimators': 100, 'xgb__num_iterations': 1000, 'xgb__random_state': 2}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.867\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "VotingClassifier(estimators=[('rfc',\n",
      "                              RandomForestClassifier(max_depth=6,\n",
      "                                                     max_leaf_nodes=10,\n",
      "                                                     min_samples_leaf=8,\n",
      "                                                     min_samples_split=20,\n",
      "                                                     n_estimators=30,\n",
      "                                                     random_state=2)),\n",
      "                             ('svc',\n",
      "                              SVC(C=0.1, gamma=0.1, probability=True,\n",
      "                                  random_state=2)),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(learning_rate=0.05,\n",
      "                                                         max_depth=6,\n",
      "                                                         min_samples_leaf=3,\n",
      "                                                         random_state=2)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(C=0.1, gamma=0.1, kernel='rbf',\n",
      "                                            max_depth=100, num_iterations=1000,\n",
      "                                            probability=True,\n",
      "                                            random_state=2))],\n",
      "                 n_jobs=-1, verbose=10, voting='soft')\n",
      "K_fold with 5 epoch : 0.8673469387755102\n",
      "[save_best_output]best_score_so_far : 0.8979591836734694\n",
      "=======================================================\n",
      "Dataset : npz/Z_RPI1807.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.8min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.8min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min finished\n",
      "len : 648 - y_test : [0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.] - y_test[:, 1] : \n",
      "len : 648 - y_test_predict : [[0.98139858 0.01860142]\n",
      " [0.05470564 0.94529436]\n",
      " [0.97529743 0.02470258]\n",
      " ...\n",
      " [0.03281075 0.96718925]\n",
      " [0.96230145 0.03769855]\n",
      " [0.96230145 0.03769855]] - y_test_predict[:, 1] : [0.01860142 0.94529436 0.02470258 0.91365836 0.9664821  0.95063972\n",
      " 0.87324993 0.7723226  0.85513568 0.02167967 0.24225012 0.09684742\n",
      " 0.9734612  0.28395388 0.97148278 0.96555142 0.96756928 0.01615236\n",
      " 0.02469639 0.97148278 0.96649529 0.95904625 0.96732723 0.11288761\n",
      " 0.96690455 0.01816259 0.95904481 0.0196101  0.96682916 0.01863789\n",
      " 0.9656377  0.91708217 0.96904048 0.9655502  0.97454262 0.93662326\n",
      " 0.01860142 0.04100128 0.01625027 0.88906894 0.02167973 0.02469639\n",
      " 0.2461562  0.95305352 0.9706552  0.01816259 0.95872194 0.02167995\n",
      " 0.01615252 0.01935608 0.04240946 0.9654764  0.95904625 0.96732723\n",
      " 0.24225012 0.02470258 0.9671998  0.91797204 0.97212023 0.01626168\n",
      " 0.04074164 0.96670068 0.03799357 0.97212023 0.01860142 0.97346311\n",
      " 0.73140327 0.01877839 0.05641676 0.08664522 0.03115096 0.01860142\n",
      " 0.13819586 0.04112897 0.01860142 0.15578462 0.96759761 0.95178288\n",
      " 0.95904481 0.8514343  0.08664526 0.87036418 0.01816259 0.96904048\n",
      " 0.0434361  0.96757895 0.01860142 0.62215184 0.96794808 0.88727273\n",
      " 0.96555142 0.97248304 0.97100066 0.97100066 0.96690455 0.97454262\n",
      " 0.01615236 0.0185839  0.02297857 0.96948666 0.86132215 0.9678768\n",
      " 0.95262243 0.04100128 0.96587876 0.82969212 0.76555723 0.84847308\n",
      " 0.01888854 0.66201218 0.03769855 0.01860142 0.97454262 0.9676189\n",
      " 0.97148278 0.63249067 0.97132993 0.96247962 0.97346311 0.01615236\n",
      " 0.01869691 0.96757895 0.96649529 0.03583112 0.01826043 0.63251636\n",
      " 0.87543329 0.01816259 0.03580896 0.9656377  0.02470274 0.96484933\n",
      " 0.01949182 0.97347397 0.96799275 0.01815687 0.70105811 0.97421696\n",
      " 0.01615236 0.02028162 0.97280883 0.03579663 0.1829067  0.02167967\n",
      " 0.02208886 0.01921441 0.01913569 0.0196101  0.01717577 0.85076944\n",
      " 0.04240946 0.03431263 0.94217821 0.01860142 0.02167973 0.02167973\n",
      " 0.01625027 0.05540451 0.02497551 0.02208803 0.04104804 0.97132993\n",
      " 0.96760197 0.91365836 0.95254397 0.83636038 0.01816259 0.97422205\n",
      " 0.2673281  0.3310626  0.97020908 0.96690396 0.97113783 0.96142575\n",
      " 0.95938686 0.94031884 0.26192411 0.9175824  0.95904625 0.8881388\n",
      " 0.01860142 0.95719334 0.96555142 0.96904048 0.50683678 0.9300118\n",
      " 0.08672341 0.91542944 0.03769855 0.91631878 0.01617898 0.01717612\n",
      " 0.01816259 0.95852974 0.04074164 0.12727545 0.04100128 0.96799275\n",
      " 0.97069864 0.02853201 0.176527   0.97129582 0.96757895 0.96492336\n",
      " 0.29358139 0.96904048 0.01877839 0.88438857 0.97132993 0.97347223\n",
      " 0.88514187 0.94827212 0.02470274 0.95768255 0.96904048 0.01860142\n",
      " 0.0185839  0.19879036 0.03427371 0.97148278 0.96723451 0.04074164\n",
      " 0.57304986 0.18096597 0.97280883 0.96307711 0.33590931 0.9656377\n",
      " 0.02794998 0.02297857 0.96757826 0.96670068 0.04240946 0.91505812\n",
      " 0.95957436 0.02208803 0.12256508 0.88598885 0.96518533 0.43657037\n",
      " 0.93593249 0.03583108 0.86785099 0.01860142 0.01615252 0.95904481\n",
      " 0.89450014 0.45814169 0.01615252 0.01930924 0.96649529 0.87808299\n",
      " 0.95852974 0.01816259 0.9656377  0.01615252 0.78119461 0.96488675\n",
      " 0.9402804  0.08698867 0.9706552  0.96168766 0.04645637 0.92400981\n",
      " 0.08705622 0.01860142 0.9656377  0.50683678 0.03431263 0.96488675\n",
      " 0.01936683 0.01615252 0.8623277  0.96670068 0.23640606 0.01842136\n",
      " 0.94029813 0.96488675 0.04297756 0.9656377  0.9676189  0.94032967\n",
      " 0.01621966 0.86469978 0.95859586 0.97347223 0.807151   0.95904481\n",
      " 0.10547582 0.96795517 0.1970968  0.96649529 0.97280883 0.01653187\n",
      " 0.03383565 0.87141102 0.70095316 0.04074164 0.89516228 0.96799275\n",
      " 0.86892587 0.81417664 0.38934056 0.02470274 0.80705554 0.84299037\n",
      " 0.80323244 0.13158602 0.932586   0.96690396 0.06368243 0.96554506\n",
      " 0.01717612 0.94799134 0.80636199 0.01816259 0.9655502  0.96757895\n",
      " 0.05547104 0.92166792 0.96904048 0.02210142 0.84229034 0.97280883\n",
      " 0.85295869 0.92377281 0.97049285 0.95904625 0.7723226  0.15578462\n",
      " 0.95472658 0.95904625 0.04240946 0.96488675 0.04726367 0.96720678\n",
      " 0.02736392 0.03199934 0.92932967 0.32616704 0.01936685 0.93543022\n",
      " 0.27458261 0.97451787 0.93543022 0.10547582 0.96649529 0.96269789\n",
      " 0.96546734 0.97033355 0.97105646 0.72718417 0.97346311 0.95747191\n",
      " 0.01876099 0.97100066 0.0162651  0.01712797 0.1356296  0.96492174\n",
      " 0.96757895 0.02756276 0.09685399 0.02208803 0.03330332 0.94032967\n",
      " 0.02456012 0.96649092 0.0230612  0.01921441 0.97148278 0.904271\n",
      " 0.91204062 0.97280883 0.9671998  0.02303935 0.06368243 0.02756276\n",
      " 0.88433039 0.97168295 0.97280883 0.95305352 0.01615252 0.0185839\n",
      " 0.97100066 0.86967635 0.94032967 0.02184315 0.96488675 0.08665266\n",
      " 0.02297857 0.88255826 0.01621966 0.86132215 0.97347397 0.79518036\n",
      " 0.8618136  0.01938294 0.04724707 0.9315507  0.95792734 0.9328063\n",
      " 0.86300824 0.0529693  0.46862693 0.10547582 0.02211222 0.93839386\n",
      " 0.01860142 0.96520253 0.94827212 0.94633466 0.94827212 0.88677749\n",
      " 0.02167995 0.08664526 0.04074164 0.96554506 0.97212023 0.01816259\n",
      " 0.66201218 0.97132993 0.04726367 0.25169479 0.96649511 0.09375436\n",
      " 0.0434361  0.79940005 0.29900614 0.62762921 0.85407828 0.28080456\n",
      " 0.92932967 0.8288795  0.01709201 0.9018139  0.36494069 0.93661968\n",
      " 0.02208931 0.96520253 0.03006134 0.80104799 0.02756276 0.91007938\n",
      " 0.97346589 0.02208931 0.83812193 0.02297857 0.9148646  0.84530428\n",
      " 0.01874005 0.92198537 0.96857902 0.01921347 0.01921441 0.01857766\n",
      " 0.01615252 0.80030471 0.95957436 0.9402804  0.95910103 0.01860142\n",
      " 0.96670068 0.96722337 0.89423307 0.9656377  0.89435273 0.96142789\n",
      " 0.03199934 0.25810391 0.96484933 0.91171529 0.14452736 0.92960889\n",
      " 0.0529693  0.01625027 0.0185839  0.05540451 0.95929442 0.0561377\n",
      " 0.03383565 0.1223967  0.02303791 0.85207986 0.01709201 0.0375863\n",
      " 0.97454284 0.95747191 0.9664821  0.01860142 0.82654073 0.80342888\n",
      " 0.91365836 0.97163658 0.02481713 0.02481713 0.01615252 0.96547304\n",
      " 0.04724589 0.6524778  0.04074164 0.9656377  0.96858665 0.96670068\n",
      " 0.32117795 0.04074164 0.95189888 0.01921441 0.93839386 0.9018139\n",
      " 0.02794998 0.96555142 0.02211207 0.17831431 0.01860142 0.93839386\n",
      " 0.94827212 0.01936757 0.96140783 0.9734707  0.81137518 0.03583146\n",
      " 0.92932934 0.21898808 0.56197695 0.91745803 0.80619075 0.2660542\n",
      " 0.66100021 0.03583112 0.03383565 0.10771147 0.95904625 0.97206413\n",
      " 0.02211232 0.24514141 0.95904481 0.9676189  0.97129582 0.08672341\n",
      " 0.91171529 0.85347271 0.96690396 0.96720678 0.02208803 0.01936679\n",
      " 0.30758781 0.34074616 0.9664821  0.93655327 0.94026216 0.63300793\n",
      " 0.97148278 0.10547582 0.9664821  0.96647605 0.24517603 0.97132993\n",
      " 0.97105646 0.7723226  0.03019866 0.74295013 0.96720678 0.86213446\n",
      " 0.05333757 0.02167995 0.05340737 0.04100128 0.81762627 0.95859586\n",
      " 0.02028162 0.01860142 0.96492336 0.01860142 0.97280883 0.9714917\n",
      " 0.97280883 0.09375436 0.96547028 0.01921509 0.93839386 0.02470034\n",
      " 0.80636199 0.02794998 0.97105646 0.96484933 0.96904048 0.96141568\n",
      " 0.02736392 0.8152638  0.01860142 0.11288761 0.17831431 0.92166792\n",
      " 0.9328063  0.96044151 0.87114892 0.95747191 0.86967635 0.96567285\n",
      " 0.87188733 0.03579663 0.96492174 0.04240946 0.9655502  0.01934419\n",
      " 0.85347271 0.91185415 0.02208803 0.87386062 0.02293778 0.96760197\n",
      " 0.93655327 0.81703027 0.86196751 0.97280883 0.38934056 0.97082207\n",
      " 0.04100128 0.89800412 0.97280883 0.96649254 0.09684742 0.91557712\n",
      " 0.02208931 0.24517603 0.04100128 0.04074164 0.15578462 0.12727545\n",
      " 0.72658037 0.97100066 0.95904481 0.01709201 0.97112997 0.96722337\n",
      " 0.08664526 0.86743468 0.86863303 0.01615236 0.97132993 0.30702451\n",
      " 0.10547582 0.27165982 0.9656377  0.96718925 0.03769855 0.03769855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Voting-Classifier': array([0.97222222, 0.98611111, 0.95486111, 0.96467391, 0.94388997,\n",
      "       0.99349923])}\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.958\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'gbc__learning_rate': 0.05, 'gbc__max_depth': 6, 'gbc__min_samples_leaf': 3, 'gbc__min_samples_split': 2, 'gbc__n_estimators': 100, 'rfc__max_depth': 6, 'rfc__max_leaf_nodes': 10, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 30, 'svc__C': 0.1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 2, 'xgb__C': 0.1, 'xgb__gamma': 0.1, 'xgb__kernel': 'rbf', 'xgb__learning_rate': 0.1, 'xgb__max_depth': 100, 'xgb__n_estimators': 100, 'xgb__num_iterations': 1000, 'xgb__random_state': 2}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.972\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "VotingClassifier(estimators=[('rfc',\n",
      "                              RandomForestClassifier(max_depth=6,\n",
      "                                                     max_leaf_nodes=10,\n",
      "                                                     min_samples_leaf=8,\n",
      "                                                     min_samples_split=20,\n",
      "                                                     n_estimators=30,\n",
      "                                                     random_state=2)),\n",
      "                             ('svc',\n",
      "                              SVC(C=0.1, gamma=0.1, probability=True,\n",
      "                                  random_state=2)),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(learning_rate=0.05,\n",
      "                                                         max_depth=6,\n",
      "                                                         min_samples_leaf=3,\n",
      "                                                         random_state=2)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(C=0.1, gamma=0.1, kernel='rbf',\n",
      "                                            max_depth=100, num_iterations=1000,\n",
      "                                            probability=True,\n",
      "                                            random_state=2))],\n",
      "                 n_jobs=-1, verbose=10, voting='soft')\n",
      "K_fold with 5 epoch : 0.9722222222222222\n",
      "[save_best_output]best_score_so_far : 0.9722222222222222\n",
      "=======================================================\n",
      "Dataset : npz/Z_RPI2241.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.0min remaining:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  4.1min remaining:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.1min finished\n",
      "len : 897 - y_test : [1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      " 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1.] - y_test[:, 1] : \n",
      "len : 897 - y_test_predict : [[0.40975543 0.59024457]\n",
      " [0.78592581 0.21407419]\n",
      " [0.76902435 0.23097565]\n",
      " ...\n",
      " [0.75951011 0.24048988]\n",
      " [0.21443315 0.78556685]\n",
      " [0.27528665 0.72471335]] - y_test_predict[:, 1] : [0.59024457 0.21407419 0.23097565 0.80641825 0.83382898 0.89333934\n",
      " 0.22730813 0.78755319 0.89370886 0.34816445 0.19274728 0.18460391\n",
      " 0.82395102 0.18950474 0.17066394 0.1905081  0.17268402 0.27956393\n",
      " 0.17545451 0.21858884 0.22619642 0.53936964 0.55479357 0.67967784\n",
      " 0.3368396  0.54473621 0.17345274 0.68239446 0.88743437 0.43371511\n",
      " 0.58789153 0.38484321 0.16942853 0.38652742 0.23504352 0.21871498\n",
      " 0.4745318  0.26443594 0.76162738 0.82879536 0.61172997 0.20272386\n",
      " 0.31062663 0.73768848 0.20559477 0.22414445 0.82164038 0.39695691\n",
      " 0.21347165 0.42781585 0.25780269 0.27314825 0.7990449  0.86987391\n",
      " 0.16824582 0.88128031 0.34613995 0.59449685 0.84118896 0.75561695\n",
      " 0.82108865 0.24342439 0.24861305 0.21768196 0.6094608  0.19917777\n",
      " 0.62128969 0.62110248 0.35934076 0.2525978  0.29394915 0.34904238\n",
      " 0.67078427 0.78317598 0.18160611 0.754808   0.58785747 0.22337559\n",
      " 0.88668632 0.68556915 0.2976551  0.69394336 0.32227277 0.77655892\n",
      " 0.45258659 0.59340277 0.68496932 0.22436546 0.89436405 0.75735508\n",
      " 0.2593443  0.27893099 0.33127816 0.26104555 0.31543841 0.74928399\n",
      " 0.69329315 0.19018406 0.86977662 0.67767382 0.87561182 0.29717555\n",
      " 0.6913674  0.18148465 0.2879582  0.23612737 0.21339859 0.80260525\n",
      " 0.89555631 0.22097033 0.52721337 0.80096709 0.35772525 0.85963193\n",
      " 0.89133871 0.72309742 0.36130893 0.21060288 0.68728256 0.50412167\n",
      " 0.89398307 0.57009396 0.235313   0.32603939 0.2317761  0.28490102\n",
      " 0.76257454 0.6480687  0.24695922 0.64002655 0.77838052 0.77726197\n",
      " 0.28958496 0.17478082 0.30166868 0.65284327 0.89716939 0.22567971\n",
      " 0.22648855 0.68414775 0.202366   0.55477766 0.22307046 0.32554343\n",
      " 0.72149943 0.78755319 0.36717114 0.45263725 0.87646754 0.22345559\n",
      " 0.20412958 0.61617249 0.66123852 0.3261947  0.75767774 0.28405107\n",
      " 0.21034969 0.26342452 0.22446941 0.53635548 0.25097955 0.18566344\n",
      " 0.59411658 0.68681191 0.26085855 0.88264965 0.28909721 0.80007638\n",
      " 0.35099945 0.38768132 0.74800796 0.27260169 0.23759639 0.45507077\n",
      " 0.26490037 0.6515578  0.7791345  0.36732713 0.87843702 0.80331385\n",
      " 0.4830714  0.44158958 0.78091727 0.24095197 0.65247068 0.87415007\n",
      " 0.87600368 0.87609518 0.36456727 0.17877247 0.83575091 0.62930714\n",
      " 0.31481747 0.24629165 0.39074329 0.68315556 0.87913716 0.32004282\n",
      " 0.22249255 0.4052837  0.87804116 0.77230623 0.66214769 0.78851966\n",
      " 0.1751301  0.2792437  0.6887491  0.20796055 0.25794313 0.56440178\n",
      " 0.18629149 0.27910828 0.5857654  0.78079327 0.2345534  0.78317363\n",
      " 0.28332457 0.72151925 0.8914017  0.65022993 0.4091931  0.24047073\n",
      " 0.2144684  0.510808   0.82302009 0.17584003 0.69942334 0.29212347\n",
      " 0.28499983 0.27546066 0.16163495 0.18228746 0.15926351 0.28305603\n",
      " 0.68756179 0.65482768 0.28319239 0.18405344 0.31150231 0.44841008\n",
      " 0.39043897 0.19558654 0.44308268 0.26925724 0.59742506 0.26391497\n",
      " 0.21040459 0.52106642 0.7648151  0.20310926 0.52009802 0.34098324\n",
      " 0.90105261 0.34375363 0.6829143  0.22799126 0.20154106 0.45878006\n",
      " 0.71183438 0.75545395 0.18649038 0.19369685 0.61058733 0.19332811\n",
      " 0.78412637 0.24984195 0.90320941 0.4012452  0.17677053 0.88059273\n",
      " 0.79629008 0.77091229 0.18806086 0.52092072 0.22575547 0.60557603\n",
      " 0.28219669 0.8856577  0.51602382 0.23788075 0.68485772 0.70056776\n",
      " 0.30557153 0.54924414 0.18906538 0.42097578 0.51655362 0.89885426\n",
      " 0.21306851 0.85034889 0.77542903 0.23299856 0.21724976 0.18010154\n",
      " 0.90008376 0.19757936 0.86296309 0.69528886 0.76231607 0.6841544\n",
      " 0.20247943 0.2584346  0.23757905 0.2530307  0.18661854 0.18538229\n",
      " 0.60576402 0.23019385 0.19561808 0.86572972 0.87146466 0.41197581\n",
      " 0.53398088 0.21279758 0.27849511 0.65674485 0.22762753 0.67445036\n",
      " 0.24920182 0.68805195 0.63054018 0.81466174 0.59874681 0.1810057\n",
      " 0.6956958  0.85958503 0.35171644 0.58455418 0.68329623 0.21462816\n",
      " 0.85542311 0.69408583 0.6723236  0.64753774 0.5868449  0.89739596\n",
      " 0.77609133 0.17774409 0.31439734 0.29163753 0.72492025 0.45408834\n",
      " 0.59162121 0.6751486  0.24694959 0.17085649 0.58240889 0.76751662\n",
      " 0.16495497 0.2447056  0.33379583 0.32010595 0.75386679 0.68192917\n",
      " 0.21080144 0.22819634 0.57024184 0.71080399 0.63771875 0.3184111\n",
      " 0.88763234 0.383657   0.20953501 0.62709208 0.66203863 0.76122458\n",
      " 0.26471206 0.76019147 0.76221267 0.26276354 0.8953445  0.52340658\n",
      " 0.54977673 0.38590652 0.78744034 0.51642702 0.87997963 0.71853327\n",
      " 0.53682117 0.72370979 0.27859713 0.8897167  0.85647001 0.26813462\n",
      " 0.86408034 0.22497871 0.64385681 0.26734101 0.67311381 0.6431895\n",
      " 0.41116799 0.39010579 0.81579552 0.82107146 0.17138245 0.29870068\n",
      " 0.28331668 0.55820616 0.2502637  0.17522343 0.87084718 0.60009301\n",
      " 0.43097266 0.48292903 0.2417164  0.39644847 0.51357509 0.38100662\n",
      " 0.4595811  0.61346744 0.19648598 0.64885013 0.75994807 0.26134878\n",
      " 0.66747119 0.33965249 0.89259092 0.23515901 0.21648423 0.19416084\n",
      " 0.24715452 0.24862191 0.76722642 0.25861206 0.88132733 0.37444354\n",
      " 0.20521301 0.21065738 0.79476247 0.63429088 0.84048156 0.42978406\n",
      " 0.63057846 0.21411809 0.21285531 0.68331629 0.82486528 0.48681952\n",
      " 0.26623587 0.34838569 0.33678895 0.23935054 0.87723883 0.19861285\n",
      " 0.87011873 0.17516783 0.22267148 0.49217416 0.70650995 0.85648362\n",
      " 0.2718332  0.17177898 0.77954267 0.18568497 0.20260164 0.2101395\n",
      " 0.88422678 0.22489625 0.1774635  0.76360671 0.85454139 0.89815123\n",
      " 0.33158712 0.8924692  0.3120668  0.35463151 0.73531921 0.25488866\n",
      " 0.16396705 0.89236044 0.23100293 0.85964909 0.86313572 0.43255988\n",
      " 0.1982076  0.78624808 0.26529216 0.24047815 0.58526641 0.87870469\n",
      " 0.85899681 0.3574239  0.48150679 0.50999005 0.22801108 0.2553706\n",
      " 0.86321033 0.5983214  0.24697331 0.74379972 0.83243394 0.3249485\n",
      " 0.35924911 0.85253435 0.27377338 0.67848803 0.45498896 0.84059457\n",
      " 0.17294096 0.32708335 0.67183683 0.81578463 0.4334413  0.45268031\n",
      " 0.2123324  0.18633506 0.85766871 0.4293754  0.74678515 0.49146855\n",
      " 0.36694932 0.3775194  0.6798087  0.2879582  0.30308313 0.86201445\n",
      " 0.32960696 0.2430076  0.19277347 0.35816474 0.45299598 0.74232125\n",
      " 0.33402199 0.24220988 0.7876571  0.86590614 0.3887607  0.37024256\n",
      " 0.87123359 0.2059701  0.70842373 0.86774329 0.30015486 0.67812304\n",
      " 0.75738022 0.5032662  0.83588499 0.2037246  0.70070686 0.19844421\n",
      " 0.4577168  0.64653326 0.89680787 0.87736668 0.87399403 0.26399278\n",
      " 0.20227575 0.28610639 0.70079082 0.73110517 0.87609518 0.86316531\n",
      " 0.21451949 0.26421092 0.44909319 0.73017386 0.29274517 0.83809977\n",
      " 0.78142588 0.83559138 0.79336694 0.79356884 0.54572952 0.37405286\n",
      " 0.36296174 0.58163889 0.20165893 0.89253462 0.81578463 0.51881266\n",
      " 0.71341    0.43363667 0.62011956 0.87965973 0.35130159 0.17160843\n",
      " 0.85965466 0.87169467 0.22573798 0.52615876 0.32000499 0.89243672\n",
      " 0.1652734  0.77557948 0.70867318 0.87164566 0.28250202 0.72092542\n",
      " 0.79563109 0.18381954 0.2025644  0.23414145 0.55656137 0.64692529\n",
      " 0.62011956 0.87920766 0.15807447 0.89482434 0.17464764 0.17450023\n",
      " 0.3374213  0.38272079 0.29635809 0.7407024  0.72232987 0.48481877\n",
      " 0.88542603 0.22705967 0.22577072 0.62527953 0.3411261  0.26975313\n",
      " 0.30488121 0.48974584 0.42432154 0.20243556 0.4041089  0.80527732\n",
      " 0.78477437 0.199643   0.59063753 0.73400209 0.87536394 0.68906737\n",
      " 0.25857822 0.79140034 0.27508896 0.32894918 0.35765959 0.42486472\n",
      " 0.77754584 0.43111345 0.76419682 0.50461567 0.18673187 0.35442318\n",
      " 0.76991486 0.29194661 0.16227779 0.80260525 0.80161414 0.16105064\n",
      " 0.66979447 0.1973691  0.39334668 0.28261391 0.66979447 0.18097123\n",
      " 0.80732805 0.51161447 0.88267359 0.47621494 0.34373964 0.7820113\n",
      " 0.70370162 0.47967976 0.34229432 0.78095332 0.86602532 0.6494232\n",
      " 0.76537491 0.38377783 0.50469407 0.26055751 0.18296234 0.78640985\n",
      " 0.87609518 0.63069211 0.2268616  0.17277122 0.18999148 0.78913588\n",
      " 0.1711549  0.66537501 0.81506019 0.15562225 0.25824706 0.26367656\n",
      " 0.16970712 0.19019447 0.29060977 0.53215291 0.84819658 0.2024055\n",
      " 0.55689369 0.65884063 0.25223027 0.84046998 0.35539973 0.30898691\n",
      " 0.28790166 0.71379211 0.52901532 0.35002551 0.45410173 0.52524025\n",
      " 0.75574073 0.615696   0.61403076 0.76452224 0.19276777 0.48236583\n",
      " 0.70240975 0.51605836 0.63711561 0.60773741 0.8673573  0.63746034\n",
      " 0.62486621 0.86584711 0.74570032 0.16684947 0.33360434 0.28628506\n",
      " 0.56521852 0.37233602 0.82228178 0.23441349 0.23299741 0.18938126\n",
      " 0.77236063 0.31048854 0.26948734 0.79505755 0.62610506 0.35059335\n",
      " 0.19623587 0.84781697 0.58332137 0.20349772 0.21240829 0.85060976\n",
      " 0.89119552 0.19342153 0.30956048 0.20617216 0.8897167  0.72845645\n",
      " 0.65945899 0.21298026 0.71933674 0.71878535 0.72202002 0.23106761\n",
      " 0.37258851 0.76618083 0.38681355 0.75840962 0.58273124 0.21155187\n",
      " 0.66011965 0.38638063 0.41107935 0.897584   0.26604277 0.32672021\n",
      " 0.64562367 0.21897163 0.76015713 0.88999351 0.2303732  0.8991577\n",
      " 0.49817097 0.2383218  0.63550408 0.69130846 0.21749656 0.62011956\n",
      " 0.19030626 0.55533687 0.89438778 0.88447306 0.22590443 0.24165529\n",
      " 0.73526852 0.25468793 0.17731743 0.46435005 0.87693886 0.61074205\n",
      " 0.87752313 0.66988633 0.40578717 0.32941703 0.24892483 0.80507681\n",
      " 0.88440706 0.66701249 0.65449697 0.56626943 0.17162443 0.86440219\n",
      " 0.41084596 0.2275261  0.77057537 0.40442127 0.70768161 0.6697917\n",
      " 0.34013048 0.281694   0.74554512 0.30549016 0.30834335 0.20886437\n",
      " 0.44496404 0.2780976  0.2367225  0.21012871 0.70658112 0.28973874\n",
      " 0.84239269 0.34471065 0.87911657 0.3896235  0.85975045 0.55499365\n",
      " 0.89293782 0.65743246 0.74225522 0.64271919 0.74854224 0.89532328\n",
      " 0.25271587 0.23980659 0.35460791 0.4131754  0.87100513 0.18915947\n",
      " 0.88548331 0.6317253  0.27977259 0.27194212 0.87164566 0.72471338\n",
      " 0.22333465 0.88709914 0.21116009 0.83949004 0.4168264  0.88459435\n",
      " 0.3775058  0.7395851  0.51730892 0.78939394 0.41195775 0.71556518\n",
      " 0.20437421 0.7582526  0.7855259  0.7710932  0.24330143 0.30293515\n",
      " 0.23140492 0.66326079 0.70897384 0.16640004 0.22278329 0.3244112\n",
      " 0.27126949 0.86068039 0.25392946 0.72586303 0.26096785 0.58170077\n",
      " 0.53011908 0.89994518 0.29821191 0.46124466 0.5404847  0.17655596\n",
      " 0.40132193 0.52489595 0.1739263  0.73472106 0.89920652 0.43534696\n",
      " 0.20659331 0.28565308 0.89415317 0.20836403 0.87920766 0.18851551\n",
      " 0.32666412 0.24468242 0.75061698 0.17299216 0.71159467 0.23727088\n",
      " 0.7664777  0.1931936  0.68915315 0.86400447 0.21043653 0.77394244\n",
      " 0.24048988 0.78556685 0.72471335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Voting-Classifier': array([0.83500557, 0.83371824, 0.8362069 , 0.82608696, 0.66974516,\n",
      "       0.90906467])}\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.815\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'gbc__learning_rate': 0.05, 'gbc__max_depth': 6, 'gbc__min_samples_leaf': 3, 'gbc__min_samples_split': 2, 'gbc__n_estimators': 100, 'rfc__max_depth': 6, 'rfc__max_leaf_nodes': 10, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 30, 'svc__C': 0.1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 2, 'xgb__C': 0.1, 'xgb__gamma': 0.1, 'xgb__kernel': 'rbf', 'xgb__learning_rate': 0.1, 'xgb__max_depth': 100, 'xgb__n_estimators': 100, 'xgb__num_iterations': 1000, 'xgb__random_state': 2}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.835\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "VotingClassifier(estimators=[('rfc',\n",
      "                              RandomForestClassifier(max_depth=6,\n",
      "                                                     max_leaf_nodes=10,\n",
      "                                                     min_samples_leaf=8,\n",
      "                                                     min_samples_split=20,\n",
      "                                                     n_estimators=30,\n",
      "                                                     random_state=2)),\n",
      "                             ('svc',\n",
      "                              SVC(C=0.1, gamma=0.1, probability=True,\n",
      "                                  random_state=2)),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(learning_rate=0.05,\n",
      "                                                         max_depth=6,\n",
      "                                                         min_samples_leaf=3,\n",
      "                                                         random_state=2)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(C=0.1, gamma=0.1, kernel='rbf',\n",
      "                                            max_depth=100, num_iterations=1000,\n",
      "                                            probability=True,\n",
      "                                            random_state=2))],\n",
      "                 n_jobs=-1, verbose=10, voting='soft')\n",
      "K_fold with 5 epoch : 0.835005574136009\n",
      "[save_best_output]best_score_so_far : 0.835005574136009\n",
      "=======================================================\n",
      "Dataset : npz/Z_NPInter.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 32.0min remaining: 48.1min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 32.2min remaining: 21.5min\n"
     ]
    }
   ],
   "source": [
    "from hyperparams import *\n",
    "from rawdata_preprocessing import *\n",
    "#from RandomForestClassifier import RF_Classifying\n",
    "#from SVMClassifier import SVM_Classifying\n",
    "\n",
    "import Bio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, roc_curve\n",
    "import math\n",
    "\n",
    "#from warnings import filterwarnings\n",
    "#filterwarnings('ignore')\n",
    "\n",
    "from Logger import *\n",
    "from save_best_output import save_best_output\n",
    "\n",
    "model_metrics = {}\n",
    "\n",
    "def calc_metrics(y_label, y_proba):\n",
    "    con_matrix = confusion_matrix(y_label, [1 if x >= 0.5 else 0 for x in y_proba])\n",
    "    TN = float(con_matrix[0][0])\n",
    "    FP = float(con_matrix[0][1])\n",
    "    FN = float(con_matrix[1][0])\n",
    "    TP = float(con_matrix[1][1])\n",
    "    P = TP + FN\n",
    "    N = TN + FP\n",
    "    Sn = TP / P if P > 0 else 0\n",
    "    Sp = TN / N if N > 0 else 0\n",
    "    Acc = (TP + TN) / (P + N) if (P + N) > 0 else 0\n",
    "    Pre = (TP) / (TP + FP) if (TP+FP) > 0 else 0\n",
    "    MCC = 0\n",
    "    tmp = math.sqrt((TP + FP) * (TP + FN)) * math.sqrt((TN + FP) * (TN + FN))\n",
    "    if tmp != 0:\n",
    "        MCC = (TP * TN - FP * FN) / tmp\n",
    "    fpr, tpr, thresholds = roc_curve(y_label, y_proba)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    return Acc, Sn, Sp, Pre, MCC, AUC\n",
    "\n",
    "def Voting_Classifying(X, y, KFOLD_TIME) :\n",
    "    #GBC_best = GBC_Classifying(X, y, KFOLD_TIME)\n",
    "    #RFC_best = RF_Classifying(X, y, KFOLD_TIME)\n",
    "    #SVMC_best = SVM_Classifying(X, y, KFOLD_TIME)\n",
    "    #XGBC_best = XGB_Classifying(X, y, KFOLD_TIME)\n",
    "    RFC_best = RandomForestClassifier(random_state=2)\n",
    "    SVMC_best = SVC(probability=True, random_state=2)\n",
    "    GBC_best = GradientBoostingClassifier(random_state=2)\n",
    "    XGBC_best = XGBClassifier(probability=True, random_state=2)\n",
    "    ABC_best = AdaBoostClassifier(random_state = 2)\n",
    "    BC_best = BaggingClassifier(random_state = 2)\n",
    "    LGBM_best = LGBMClassifier(random_state = 2)\n",
    "    \n",
    "    VC = VotingClassifier(estimators=[\n",
    "        #('ada', ABC_best), \n",
    "        #                              ('bc', BC_best),\n",
    "        #                              ('lgbm', LGBM_best),\n",
    "                                      ('rfc', RFC_best), \n",
    "                                      ('svc', SVMC_best), \n",
    "                                      ('gbc', GBC_best), \n",
    "                                      ('xgb', XGBC_best)\n",
    "                                      ], \n",
    "                          voting='soft', n_jobs=-1, verbose=10)\n",
    "    param_range = [0.1, 1.0]\n",
    "    param_grid = {\n",
    "        'gbc__n_estimators' : [100], 'gbc__max_depth' : [6], 'gbc__min_samples_leaf': [3], 'gbc__min_samples_split' : [2], 'gbc__learning_rate' : [0.05],\n",
    "        'svc__kernel' : ['rbf'], 'svc__C' : [0.1], 'svc__gamma': [0.1], 'svc__random_state' : [2],\n",
    "        'xgb__kernel' : ['rbf'], 'xgb__C' : [0.1], 'xgb__num_iterations': [1000], 'xgb__gamma':[0.1], 'xgb__random_state' : [2], 'xgb__learning_rate' : [0.1], 'xgb__n_estimators' : [100], 'xgb__max_depth' : [100],\n",
    "        'rfc__n_estimators' : [30],'rfc__max_depth' : [6],'rfc__min_samples_leaf' : [8],'rfc__min_samples_split' : [20], 'rfc__max_leaf_nodes' : [10],\n",
    "        #'ada__base_estimator' : [RFC_best, SVMC_best], 'ada__n_estimators' : [10], 'ada__learning_rate' : [0.01],\n",
    "        #'bc__base_estimator' : [SVMC_best, GBC_best, XGBC_best, ABC_best], 'bc__n_estimators' : [10],\n",
    "        #'lgbm__n_estimators' : [10], 'lgbm__min_samples_leaf' : [3], 'lgbm__min_samples_split' : [2], 'lgbm__learning_rate' : [0.01]\n",
    "    }\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsVC = GridSearchCV(estimator=VC, param_grid=param_grid, cv=KFOLD_TIME, n_jobs = -1, verbose=10)\n",
    "\n",
    "    gsVC = gsVC.fit(X_train,y_train)\n",
    "    score = gsVC.score(X_test, y_test)\n",
    "    y_test_predict = gsVC.predict_proba(X_test)\n",
    "    logger.debug('len : {0} - y_test : {1} - y_test[:, 1] : '.format(len(y_test), y_test))\n",
    "    logger.debug('len : {0} - y_test_predict : {1} - y_test_predict[:, 1] : {2}'.format(len(y_test_predict), y_test_predict, y_test_predict[:, 1]))\n",
    "    model_metrics['Voting-Classifier'] = np.array(calc_metrics(y_test, y_test_predict[:, 1]))\n",
    "    logger.debug(model_metrics)\n",
    "    \n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsVC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsVC.best_params_))\n",
    "    logger.warning('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsVC.best_estimator_))\n",
    "    \n",
    "    return score, gsVC.best_params_, gsVC.best_estimator_\n",
    "\n",
    "\n",
    "def Bagging_Classifying(X, y, KFOLD_TIME) :\n",
    "    BC = BaggingClassifier()\n",
    "    \n",
    "\"\"\"\n",
    "def GBC_Classifying(X, y, KFOLD_TIME) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"GBC_Classifying ... \")\n",
    "    gbrt = GradientBoostingClassifier(random_state = 0)\n",
    "    '''\n",
    "    param_grid = {\n",
    "        'n_estimators' : [100, 200], \n",
    "        'max_depth' : [6,8,10,12], \n",
    "        'min_samples_leaf': [3,5,7,10], \n",
    "        'min_samples_split' : [2,3,5,10], \n",
    "        'learning_rate' : [0.05, 0.1, 0.2]\n",
    "    }\n",
    "    '''\n",
    "    param_grid = {'n_estimators' : [100], 'max_depth' : [6], 'min_samples_leaf': [3], 'min_samples_split' : [2], 'learning_rate' : [0.05]}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsGBRT = GridSearchCV(gbrt, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=6, verbose=2)\n",
    "    \n",
    "    '''\n",
    "    gsGBRT.fit(X_train, y_train)\n",
    "    score = gsGBRT.score(X_test, y_test)\n",
    "    print('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsGBRT.best_score_))\n",
    "    print('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsGBRT.best_params_))\n",
    "    print('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    print('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsGBRT.best_estimator_))\n",
    "    '''\n",
    "    return score, gsGBRT.best_params_, gsGBRT.best_estimator_\n",
    "\n",
    "def SVM_Classifying(X, y, KFOLD_TIME) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"SVM_Classifying ... \")\n",
    "    SVMC = SVC(probability=True)\n",
    "    param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    #param_range = [0.1, 1.0]\n",
    "    '''\n",
    "    param_grid = [\n",
    "        {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['poly'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['linear'], 'C' : param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['sigmoid'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] }\n",
    "    ]\n",
    "    '''\n",
    "    param_grid = [\n",
    "        {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] }  \n",
    "    ]\n",
    "\n",
    "    #['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsSVMC = GridSearchCV(SVMC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=6, verbose=2)\n",
    "\n",
    "\n",
    "    '''\n",
    "    gsSVMC.fit(X, y)\n",
    "    score = gsSVMC.score(X_test, y_test)\n",
    "\n",
    "    SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "    print(\"best score : {}\".format(gsSVMC.best_score_))\n",
    "    print(\"best parameters : {}\".format(gsSVMC.best_params_))\n",
    "    print(\"train set score : {}\".format(gsSVMC.score(X, y)))\n",
    "    '''\n",
    "    return score, gsSVMC.best_params_, gsSVMC.best_estimator_\n",
    "\"\"\"\n",
    "def XGB_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"XGB_Classifying ...\")\n",
    "    XGBC = XGBClassifier(probability=True)\n",
    "    param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    '''\n",
    "    param_grid = {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01, 0.05, 0.1, 0.15, 0.2], \n",
    "                  'n_estimators' : [100, 200, 400, 600], \n",
    "                  'max_depth' : [4,6,8,10,12] }\n",
    "    \n",
    "    param_grid = {'kernel' : ['rbf'], 'C' : param_range, 'gamma':[0.1], 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01], \n",
    "                  'n_estimators' : [100], \n",
    "                  'max_depth' : [4]}\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsXGBC = GridSearchCV(XGBC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsXGBC.fit(X_train, y_train)\n",
    "    score = gsXGBC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsXGBC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsXGBC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsXGBC.best_estimator_))\n",
    "    \n",
    "    return score, gsXGBC.best_params_, gsXGBC.best_estimator_\n",
    "\n",
    "def LGBM_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"LGBM_Classifying ...\")\n",
    "    LGBC = LGBMClassifier(random_state = 2)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsLGBM = GridSearchCV(LGBC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsLGBM.fit(X_train, y_train)\n",
    "    score = gsLGBM.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsLGBM.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsLGBM.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsLGBM.best_estimator_))\n",
    "    \n",
    "    return score, gsLGBM.best_params_, gsLGBM.best_estimator_\n",
    "\n",
    "def RF_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"RF_Classifying ... \")\n",
    "    RFC = RandomForestClassifier(random_state=2)\n",
    "\n",
    "    \n",
    "    param_grid = {'n_estimators' : [10],'max_depth' : [6],'min_samples_leaf' : [8],'min_samples_split' : [8], 'max_leaf_nodes' : [10]}\n",
    "\n",
    "    kfold = KFold(n_splits=KFOLD_TIME, shuffle=True, random_state=11)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    \n",
    "    gsRFC = GridSearchCV(RFC, param_grid = param_grid, cv=kfold,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsRFC.fit(X_train, y_train)\n",
    "    # X_train, y_train 을 0.8:0.2 이런식으로 나눠서 cv 시킨다는 뜻인듯 ?\n",
    "    \n",
    "    score = gsRFC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsRFC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsRFC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsRFC.best_estimator_))\n",
    "    \n",
    "    #return gsRFC\n",
    "    return score, gsRFC.best_params_, gsRFC.best_estimator_\n",
    "\n",
    "def LR_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"LogisticRegressionCV_Classifying ... \")\n",
    "    \n",
    "    LRC = LogisticRegressionCV(random_state = 2)\n",
    "    param_range = [0.01 ,0.1, 1, 10, 100]\n",
    "    param_grid = {'C' : param_range, 'gamma':[0.1], 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01], \n",
    "                  'n_estimators' : [100], \n",
    "                  'max_depth' : [4]}\n",
    "    gsLRC = GridSearchCV(LRC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsLRC.fit(X_train, y_train)\n",
    "    \n",
    "    score = gsLRC.score(X_test, y_test)\n",
    "    \n",
    "    \n",
    "    score = gsLRC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsLRC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsLRC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsLRC.best_estimator_))\n",
    "    return score, gsLRC.best_params_, gsLRC.best_estimator_\n",
    "\n",
    "KFOLD_TIME = 5\n",
    "cv=KFold(n_splits=3,random_state=5,shuffle=True)\n",
    "\n",
    "p_feature_names = ['A', 'AA', 'AAA', 'AAB', 'AAC', 'AAD', 'AAE', 'AAF', 'AAG', 'AB', 'ABA', 'ABB', 'ABC', 'ABD', 'ABE', 'ABF', 'ABG', 'AC', 'ACA', 'ACB', 'ACC', 'ACD', 'ACE', 'ACF', 'ACG', 'AD', 'ADA', 'ADB', 'ADC', 'ADD', 'ADE', 'ADF', 'ADG', 'AE', 'AEA', 'AEB', 'AEC', 'AED', 'AEE', 'AEF', 'AEG', 'AF', 'AFA', 'AFB', 'AFC', 'AFD', 'AFE', 'AFF', 'AFG', 'AG', 'AGA', 'AGB', 'AGC', 'AGD', 'AGE', 'AGF', 'AGG', 'B', 'BA', 'BAA', 'BAB', 'BAC', 'BAD', 'BAE', 'BAF', 'BAG', 'BB', 'BBA', 'BBB', 'BBC', 'BBD', 'BBE', 'BBF', 'BBG', 'BC', 'BCA', 'BCB', 'BCC', 'BCD', 'BCE', 'BCF', 'BCG', 'BD', 'BDA', 'BDB', 'BDC', 'BDD', 'BDE', 'BDF', 'BDG', 'BE', 'BEA', 'BEB', 'BEC', 'BED', 'BEE', 'BEF', 'BEG', 'BF', 'BFA', 'BFB', 'BFC', 'BFD', 'BFE', 'BFF', 'BFG', 'BG', 'BGA', 'BGB', 'BGC', 'BGD', 'BGE', 'BGF', 'BGG', 'C', 'CA', 'CAA', 'CAB', 'CAC', 'CAD', 'CAE', 'CAF', 'CAG', 'CB', 'CBA', 'CBB', 'CBC', 'CBD', 'CBE', 'CBF', 'CBG', 'CC', 'CCA', 'CCB', 'CCC', 'CCD', 'CCE', 'CCF', 'CCG', 'CD', 'CDA', 'CDB', 'CDC', 'CDD', 'CDE', 'CDF', 'CDG', 'CE', 'CEA', 'CEB', 'CEC', 'CED', 'CEE', 'CEF', 'CEG', 'CF', 'CFA', 'CFB', 'CFC', 'CFD', 'CFE', 'CFF', 'CFG', 'CG', 'CGA', 'CGB', 'CGC', 'CGD', 'CGE', 'CGF', 'CGG', 'D', 'DA', 'DAA', 'DAB', 'DAC', 'DAD', 'DAE', 'DAF', 'DAG', 'DB', 'DBA', 'DBB', 'DBC', 'DBD', 'DBE', 'DBF', 'DBG', 'DC', 'DCA', 'DCB', 'DCC', 'DCD', 'DCE', 'DCF', 'DCG', 'DD', 'DDA', 'DDB', 'DDC', 'DDD', 'DDE', 'DDF', 'DDG', 'DE', 'DEA', 'DEB', 'DEC', 'DED', 'DEE', 'DEF', 'DEG', 'DF', 'DFA', 'DFB', 'DFC', 'DFD', 'DFE', 'DFF', 'DFG', 'DG', 'DGA', 'DGB', 'DGC', 'DGD', 'DGE', 'DGF', 'DGG', 'E', 'EA', 'EAA', 'EAB', 'EAC', 'EAD', 'EAE', 'EAF', 'EAG', 'EB', 'EBA', 'EBB', 'EBC', 'EBD', 'EBE', 'EBF', 'EBG', 'EC', 'ECA', 'ECB', 'ECC', 'ECD', 'ECE', 'ECF', 'ECG', 'ED', 'EDA', 'EDB', 'EDC', 'EDD', 'EDE', 'EDF', 'EDG', 'EE', 'EEA', 'EEB', 'EEC', 'EED', 'EEE', 'EEF', 'EEG', 'EF', 'EFA', 'EFB', 'EFC', 'EFD', 'EFE', 'EFF', 'EFG', 'EG', 'EGA', 'EGB', 'EGC', 'EGD', 'EGE', 'EGF', 'EGG', 'F', 'FA', 'FAA', 'FAB', 'FAC', 'FAD', 'FAE', 'FAF', 'FAG', 'FB', 'FBA', 'FBB', 'FBC', 'FBD', 'FBE', 'FBF', 'FBG', 'FC', 'FCA', 'FCB', 'FCC', 'FCD', 'FCE', 'FCF', 'FCG', 'FD', 'FDA', 'FDB', 'FDC', 'FDD', 'FDE', 'FDF', 'FDG', 'FE', 'FEA', 'FEB', 'FEC', 'FED', 'FEE', 'FEF', 'FEG', 'FF', 'FFA', 'FFB', 'FFC', 'FFD', 'FFE', 'FFF', 'FFG', 'FG', 'FGA', 'FGB', 'FGC', 'FGD', 'FGE', 'FGF', 'FGG', 'G', 'GA', 'GAA', 'GAB', 'GAC', 'GAD', 'GAE', 'GAF', 'GAG', 'GB', 'GBA', 'GBB', 'GBC', 'GBD', 'GBE', 'GBF', 'GBG', 'GC', 'GCA', 'GCB', 'GCC', 'GCD', 'GCE', 'GCF', 'GCG', 'GD', 'GDA', 'GDB', 'GDC', 'GDD', 'GDE', 'GDF', 'GDG', 'GE', 'GEA', 'GEB', 'GEC', 'GED', 'GEE', 'GEF', 'GEG', 'GF', 'GFA', 'GFB', 'GFC', 'GFD', 'GFE', 'GFF', 'GFG', 'GG', 'GGA', 'GGB', 'GGC', 'GGD', 'GGE', 'GGF', 'GGG']\n",
    "r_feature_names = ['A', 'AA', 'AAA', 'AAAA', 'AAAC', 'AAAG', 'AAAU', 'AAC', 'AACA', 'AACC', 'AACG', 'AACU', 'AAG', 'AAGA', 'AAGC', 'AAGG', 'AAGU', 'AAU', 'AAUA', 'AAUC', 'AAUG', 'AAUU', 'AC', 'ACA', 'ACAA', 'ACAC', 'ACAG', 'ACAU', 'ACC', 'ACCA', 'ACCC', 'ACCG', 'ACCU', 'ACG', 'ACGA', 'ACGC', 'ACGG', 'ACGU', 'ACU', 'ACUA', 'ACUC', 'ACUG', 'ACUU', 'AG', 'AGA', 'AGAA', 'AGAC', 'AGAG', 'AGAU', 'AGC', 'AGCA', 'AGCC', 'AGCG', 'AGCU', 'AGG', 'AGGA', 'AGGC', 'AGGG', 'AGGU', 'AGU', 'AGUA', 'AGUC', 'AGUG', 'AGUU', 'AU', 'AUA', 'AUAA', 'AUAC', 'AUAG', 'AUAU', 'AUC', 'AUCA', 'AUCC', 'AUCG', 'AUCU', 'AUG', 'AUGA', 'AUGC', 'AUGG', 'AUGU', 'AUU', 'AUUA', 'AUUC', 'AUUG', 'AUUU', 'C', 'CA', 'CAA', 'CAAA', 'CAAC', 'CAAG', 'CAAU', 'CAC', 'CACA', 'CACC', 'CACG', 'CACU', 'CAG', 'CAGA', 'CAGC', 'CAGG', 'CAGU', 'CAU', 'CAUA', 'CAUC', 'CAUG', 'CAUU', 'CC', 'CCA', 'CCAA', 'CCAC', 'CCAG', 'CCAU', 'CCC', 'CCCA', 'CCCC', 'CCCG', 'CCCU', 'CCG', 'CCGA', 'CCGC', 'CCGG', 'CCGU', 'CCU', 'CCUA', 'CCUC', 'CCUG', 'CCUU', 'CG', 'CGA', 'CGAA', 'CGAC', 'CGAG', 'CGAU', 'CGC', 'CGCA', 'CGCC', 'CGCG', 'CGCU', 'CGG', 'CGGA', 'CGGC', 'CGGG', 'CGGU', 'CGU', 'CGUA', 'CGUC', 'CGUG', 'CGUU', 'CU', 'CUA', 'CUAA', 'CUAC', 'CUAG', 'CUAU', 'CUC', 'CUCA', 'CUCC', 'CUCG', 'CUCU', 'CUG', 'CUGA', 'CUGC', 'CUGG', 'CUGU', 'CUU', 'CUUA', 'CUUC', 'CUUG', 'CUUU', 'G', 'GA', 'GAA', 'GAAA', 'GAAC', 'GAAG', 'GAAU', 'GAC', 'GACA', 'GACC', 'GACG', 'GACU', 'GAG', 'GAGA', 'GAGC', 'GAGG', 'GAGU', 'GAU', 'GAUA', 'GAUC', 'GAUG', 'GAUU', 'GC', 'GCA', 'GCAA', 'GCAC', 'GCAG', 'GCAU', 'GCC', 'GCCA', 'GCCC', 'GCCG', 'GCCU', 'GCG', 'GCGA', 'GCGC', 'GCGG', 'GCGU', 'GCU', 'GCUA', 'GCUC', 'GCUG', 'GCUU', 'GG', 'GGA', 'GGAA', 'GGAC', 'GGAG', 'GGAU', 'GGC', 'GGCA', 'GGCC', 'GGCG', 'GGCU', 'GGG', 'GGGA', 'GGGC', 'GGGG', 'GGGU', 'GGU', 'GGUA', 'GGUC', 'GGUG', 'GGUU', 'GU', 'GUA', 'GUAA', 'GUAC', 'GUAG', 'GUAU', 'GUC', 'GUCA', 'GUCC', 'GUCG', 'GUCU', 'GUG', 'GUGA', 'GUGC', 'GUGG', 'GUGU', 'GUU', 'GUUA', 'GUUC', 'GUUG', 'GUUU', 'U', 'UA', 'UAA', 'UAAA', 'UAAC', 'UAAG', 'UAAU', 'UAC', 'UACA', 'UACC', 'UACG', 'UACU', 'UAG', 'UAGA', 'UAGC', 'UAGG', 'UAGU', 'UAU', 'UAUA', 'UAUC', 'UAUG', 'UAUU', 'UC', 'UCA', 'UCAA', 'UCAC', 'UCAG', 'UCAU', 'UCC', 'UCCA', 'UCCC', 'UCCG', 'UCCU', 'UCG', 'UCGA', 'UCGC', 'UCGG', 'UCGU', 'UCU', 'UCUA', 'UCUC', 'UCUG', 'UCUU', 'UG', 'UGA', 'UGAA', 'UGAC', 'UGAG', 'UGAU', 'UGC', 'UGCA', 'UGCC', 'UGCG', 'UGCU', 'UGG', 'UGGA', 'UGGC', 'UGGG', 'UGGU', 'UGU', 'UGUA', 'UGUC', 'UGUG', 'UGUU', 'UU', 'UUA', 'UUAA', 'UUAC', 'UUAG', 'UUAU', 'UUC', 'UUCA', 'UUCC', 'UUCG', 'UUCU', 'UUG', 'UUGA', 'UUGC', 'UUGG', 'UUGU', 'UUU', 'UUUA', 'UUUC', 'UUUG', 'UUUU']\n",
    "xgb_r_feature_names = ['r_A', 'r_AA', 'r_AAA', 'r_AAAA', 'r_AAAC', 'r_AAAG', 'r_AAAU', 'r_AAC', 'r_AACA', 'r_AACC', 'r_AACG', 'r_AACU', 'r_AAG', 'r_AAGA', 'r_AAGC', 'r_AAGG', 'r_AAGU', 'r_AAU', 'r_AAUA', 'r_AAUC', 'r_AAUG', 'r_AAUU', 'r_AC', 'r_ACA', 'r_ACAA', 'r_ACAC', 'r_ACAG', 'r_ACAU', 'r_ACC', 'r_ACCA', 'r_ACCC', 'r_ACCG', 'r_ACCU', 'r_ACG', 'r_ACGA', 'r_ACGC', 'r_ACGG', 'r_ACGU', 'r_ACU', 'r_ACUA', 'r_ACUC', 'r_ACUG', 'r_ACUU', 'r_AG', 'r_AGA', 'r_AGAA', 'r_AGAC', 'r_AGAG', 'r_AGAU', 'r_AGC', 'r_AGCA', 'r_AGCC', 'r_AGCG', 'r_AGCU', 'r_AGG', 'r_AGGA', 'r_AGGC', 'r_AGGG', 'r_AGGU', 'r_AGU', 'r_AGUA', 'r_AGUC', 'r_AGUG', 'r_AGUU', 'r_AU', 'r_AUA', 'r_AUAA', 'r_AUAC', 'r_AUAG', 'r_AUAU', 'r_AUC', 'r_AUCA', 'r_AUCC', 'r_AUCG', 'r_AUCU', 'r_AUG', 'r_AUGA', 'r_AUGC', 'r_AUGG', 'r_AUGU', 'r_AUU', 'r_AUUA', 'r_AUUC', 'r_AUUG', 'r_AUUU', 'r_C', 'r_CA', 'r_CAA', 'r_CAAA', 'r_CAAC', 'r_CAAG', 'r_CAAU', 'r_CAC', 'r_CACA', 'r_CACC', 'r_CACG', 'r_CACU', 'r_CAG', 'r_CAGA', 'r_CAGC', 'r_CAGG', 'r_CAGU', 'r_CAU', 'r_CAUA', 'r_CAUC', 'r_CAUG', 'r_CAUU', 'r_CC', 'r_CCA', 'r_CCAA', 'r_CCAC', 'r_CCAG', 'r_CCAU', 'r_CCC', 'r_CCCA', 'r_CCCC', 'r_CCCG', 'r_CCCU', 'r_CCG', 'r_CCGA', 'r_CCGC', 'r_CCGG', 'r_CCGU', 'r_CCU', 'r_CCUA', 'r_CCUC', 'r_CCUG', 'r_CCUU', 'r_CG', 'r_CGA', 'r_CGAA', 'r_CGAC', 'r_CGAG', 'r_CGAU', 'r_CGC', 'r_CGCA', 'r_CGCC', 'r_CGCG', 'r_CGCU', 'r_CGG', 'r_CGGA', 'r_CGGC', 'r_CGGG', 'r_CGGU', 'r_CGU', 'r_CGUA', 'r_CGUC', 'r_CGUG', 'r_CGUU', 'r_CU', 'r_CUA', 'r_CUAA', 'r_CUAC', 'r_CUAG', 'r_CUAU', 'r_CUC', 'r_CUCA', 'r_CUCC', 'r_CUCG', 'r_CUCU', 'r_CUG', 'r_CUGA', 'r_CUGC', 'r_CUGG', 'r_CUGU', 'r_CUU', 'r_CUUA', 'r_CUUC', 'r_CUUG', 'r_CUUU', 'r_G', 'r_GA', 'r_GAA', 'r_GAAA', 'r_GAAC', 'r_GAAG', 'r_GAAU', 'r_GAC', 'r_GACA', 'r_GACC', 'r_GACG', 'r_GACU', 'r_GAG', 'r_GAGA', 'r_GAGC', 'r_GAGG', 'r_GAGU', 'r_GAU', 'r_GAUA', 'r_GAUC', 'r_GAUG', 'r_GAUU', 'r_GC', 'r_GCA', 'r_GCAA', 'r_GCAC', 'r_GCAG', 'r_GCAU', 'r_GCC', 'r_GCCA', 'r_GCCC', 'r_GCCG', 'r_GCCU', 'r_GCG', 'r_GCGA', 'r_GCGC', 'r_GCGG', 'r_GCGU', 'r_GCU', 'r_GCUA', 'r_GCUC', 'r_GCUG', 'r_GCUU', 'r_GG', 'r_GGA', 'r_GGAA', 'r_GGAC', 'r_GGAG', 'r_GGAU', 'r_GGC', 'r_GGCA', 'r_GGCC', 'r_GGCG', 'r_GGCU', 'r_GGG', 'r_GGGA', 'r_GGGC', 'r_GGGG', 'r_GGGU', 'r_GGU', 'r_GGUA', 'r_GGUC', 'r_GGUG', 'r_GGUU', 'r_GU', 'r_GUA', 'r_GUAA', 'r_GUAC', 'r_GUAG', 'r_GUAU', 'r_GUC', 'r_GUCA', 'r_GUCC', 'r_GUCG', 'r_GUCU', 'r_GUG', 'r_GUGA', 'r_GUGC', 'r_GUGG', 'r_GUGU', 'r_GUU', 'r_GUUA', 'r_GUUC', 'r_GUUG', 'r_GUUU', 'r_U', 'r_UA', 'r_UAA', 'r_UAAA', 'r_UAAC', 'r_UAAG', 'r_UAAU', 'r_UAC', 'r_UACA', 'r_UACC', 'r_UACG', 'r_UACU', 'r_UAG', 'r_UAGA', 'r_UAGC', 'r_UAGG', 'r_UAGU', 'r_UAU', 'r_UAUA', 'r_UAUC', 'r_UAUG', 'r_UAUU', 'r_UC', 'r_UCA', 'r_UCAA', 'r_UCAC', 'r_UCAG', 'r_UCAU', 'r_UCC', 'r_UCCA', 'r_UCCC', 'r_UCCG', 'r_UCCU', 'r_UCG', 'r_UCGA', 'r_UCGC', 'r_UCGG', 'r_UCGU', 'r_UCU', 'r_UCUA', 'r_UCUC', 'r_UCUG', 'r_UCUU', 'r_UG', 'r_UGA', 'r_UGAA', 'r_UGAC', 'r_UGAG', 'r_UGAU', 'r_UGC', 'r_UGCA', 'r_UGCC', 'r_UGCG', 'r_UGCU', 'r_UGG', 'r_UGGA', 'r_UGGC', 'r_UGGG', 'r_UGGU', 'r_UGU', 'r_UGUA', 'r_UGUC', 'r_UGUG', 'r_UGUU', 'r_UU', 'r_UUA', 'r_UUAA', 'r_UUAC', 'r_UUAG', 'r_UUAU', 'r_UUC', 'r_UUCA', 'r_UUCC', 'r_UUCG', 'r_UUCU', 'r_UUG', 'r_UUGA', 'r_UUGC', 'r_UUGG', 'r_UUGU', 'r_UUU', 'r_UUUA', 'r_UUUC', 'r_UUUG', 'r_UUUU']\n",
    "\n",
    "train_combined_arr = []\n",
    "val_combined_arr = []\n",
    "\n",
    "def classify(npz_path, param_grid) :\n",
    "    logger.debug(\"Dataset : {}\".format(npz_path))\n",
    "    mydata = np.load(npz_path)\n",
    "    XP = mydata['XP']\n",
    "    XR = mydata['XR']\n",
    "    Y = mydata['Y']\n",
    "\n",
    "    #combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_feature_names + r_feature_names + ['target'])\n",
    "    combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_feature_names + xgb_r_feature_names + ['target'])\n",
    "\n",
    "\n",
    "    features = list(combined_pd.columns[:-1])\n",
    "    X = combined_pd[features]\n",
    "    y = combined_pd['target']\n",
    "\n",
    "    return Voting_Classifying(X, y, KFOLD_TIME)\n",
    "    #return RF_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "    #return XGB_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "    #return LGBM_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "\n",
    "def classify_and_print_NPInter(dataset):\n",
    "    logger.debug(\"=======================================================\")\n",
    "    best_score, best_params, best_model = classify(dataset[\"NPInter\"], PARAM_GRID[\"NPInter\"][\"RFC\"])\n",
    "    logger.warning(\"K_fold with {0} epoch : {1}\".format(KFOLD_TIME, best_score))\n",
    "    save_best_output(dataset[\"NPInter\"], best_score, best_params, str(best_model).replace('\\n', ''))\n",
    "    \n",
    "def classify_and_print_RPI(size, dataset):\n",
    "    logger.debug(\"=======================================================\")\n",
    "    best_score, best_params, best_model = classify(dataset[\"RPI\"][size], PARAM_GRID[\"RPI\"][size][\"RFC\"])\n",
    "    logger.warning(\"K_fold with {0} epoch : {1}\".format(KFOLD_TIME, best_score))\n",
    "\n",
    "    save_best_output(dataset[\"RPI\"][size], best_score, best_params, str(best_model).replace('\\n', ''))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = Z_NPZ_PATH\n",
    "    logger.debug(\"Classification is about to start ... \")\n",
    "    classify_and_print_RPI(369, dataset)\n",
    "    classify_and_print_RPI(488, dataset)\n",
    "    classify_and_print_RPI(1807, dataset)\n",
    "    classify_and_print_RPI(2241, dataset)\n",
    "    classify_and_print_NPInter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
