{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1th try\n",
      "Classification is about to start ... \n",
      "=======================================================\n",
      "Dataset : npz/STRUCT_RPI488.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   16.2s remaining:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   16.2s remaining:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.6s finished\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.846\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'gbc__learning_rate': 0.1, 'gbc__max_depth': 100, 'gbc__max_features': 250, 'gbc__min_samples_leaf': 3, 'gbc__min_samples_split': 10, 'gbc__n_estimators': 60, 'lgbm__boosting': 'dart', 'lgbm__learning_rate': 0.01, 'lgbm__max_depth': 100, 'lgbm__num_iterations': 1000, 'rfc__max_depth': 6, 'rfc__max_leaf_nodes': 10, 'rfc__min_samples_leaf': 7, 'rfc__min_samples_split': 13, 'rfc__n_estimators': 125, 'svc__C': 0.01, 'svc__gamma': 0.01, 'svc__kernel': 'linear', 'xgb__boosting': 'gblinear', 'xgb__learning_rate': 0.075, 'xgb__max_depth': 100, 'xgb__num_iterations': 1000}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.908\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "VotingClassifier(estimators=[('lgbm',\n",
      "                              LGBMClassifier(boosting='dart',\n",
      "                                             learning_rate=0.01, max_depth=100,\n",
      "                                             num_iterations=1000)),\n",
      "                             ('rfc',\n",
      "                              RandomForestClassifier(max_depth=6,\n",
      "                                                     max_leaf_nodes=10,\n",
      "                                                     min_samples_leaf=7,\n",
      "                                                     min_samples_split=13,\n",
      "                                                     n_estimators=125)),\n",
      "                             ('svc',\n",
      "                              SVC(C=0.01, gamma=0.01, kernel='linear',\n",
      "                                  probability=True)),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(max_depth=100,\n",
      "                                                         max_features=250,\n",
      "                                                         min_samples_leaf=3,\n",
      "                                                         min_samples_split=10,\n",
      "                                                         n_estimators=60)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(boosting='gblinear',\n",
      "                                            learning_rate=0.075, max_depth=100,\n",
      "                                            num_iterations=1000,\n",
      "                                            probability=True,\n",
      "                                            random_state=2))],\n",
      "                 n_jobs=-1, verbose=10, voting='soft')\n",
      "GridSearchCV를 이용한 최고 score set ==> \n",
      "[0.90816327 0.85714286 0.95918367 0.95454545 0.82060994 0.94127447]\n",
      "K_fold with 5 epoch : 0.9081632653061225\n",
      "[save_best_output]best_score_so_far : 0.8979591836734694\n",
      "[save_best_output]Best Score of dataset RPI488 updated with score 0.9081632653061225\n",
      "=======================================================\n",
      "Dataset : npz/STRUCT_RPI1807.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "from hyperparams import *\n",
    "from rawdata_preprocessing import *\n",
    "from features import *\n",
    "\n",
    "import Bio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, roc_curve\n",
    "import math\n",
    "\n",
    "#from warnings import filterwarnings\n",
    "#filterwarnings('ignore')\n",
    "\n",
    "from Logger import *\n",
    "from save_best_output import save_best_output\n",
    "\n",
    "model_metrics = {\n",
    "    0 : [],\n",
    "    1 : [],\n",
    "    2 : [],\n",
    "    3 : [],\n",
    "    4 : [],\n",
    "    5 : [],\n",
    "    6 : [],\n",
    "    7 : [],\n",
    "    8 : [],\n",
    "    9 : [],\n",
    "    \"mean\" : []\n",
    "}\n",
    "KFOLD_TIME = 5\n",
    "cv=KFold(n_splits=3,random_state=5,shuffle=True)\n",
    "\n",
    "def calc_metrics(y_label, y_proba):\n",
    "    con_matrix = confusion_matrix(y_label, [1 if x >= 0.5 else 0 for x in y_proba])\n",
    "    TN = float(con_matrix[0][0])\n",
    "    FP = float(con_matrix[0][1])\n",
    "    FN = float(con_matrix[1][0])\n",
    "    TP = float(con_matrix[1][1])\n",
    "    P = TP + FN\n",
    "    N = TN + FP\n",
    "    Sn = TP / P if P > 0 else 0\n",
    "    Sp = TN / N if N > 0 else 0\n",
    "    Acc = (TP + TN) / (P + N) if (P + N) > 0 else 0\n",
    "    Pre = (TP) / (TP + FP) if (TP+FP) > 0 else 0\n",
    "    MCC = 0\n",
    "    tmp = math.sqrt((TP + FP) * (TP + FN)) * math.sqrt((TN + FP) * (TN + FN))\n",
    "    if tmp != 0:\n",
    "        MCC = (TP * TN - FP * FN) / tmp\n",
    "    fpr, tpr, thresholds = roc_curve(y_label, y_proba)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    return Acc, Sn, Sp, Pre, MCC, AUC\n",
    "\n",
    "def Voting_Classifying(X, y, param_grid) :\n",
    "    RFC_best = RandomForestClassifier(random_state=None)\n",
    "    SVMC_best = SVC(probability=True, random_state=None)\n",
    "    GBC_best = GradientBoostingClassifier(random_state=None)\n",
    "    XGBC_best = XGBClassifier(probability=True, random_state=2)\n",
    "    LGBM_best = LGBMClassifier(random_state = None)\n",
    "    \n",
    "    ABC_best = AdaBoostClassifier(random_state = 2)\n",
    "    BC_best = BaggingClassifier(random_state = None)\n",
    "    \n",
    "    VC = VotingClassifier(estimators=[\n",
    "        #('ada', ABC_best), \n",
    "        #                              ('bc', BC_best),\n",
    "                                      ('lgbm', LGBM_best),\n",
    "                                      ('rfc', RFC_best), \n",
    "                                      ('svc', SVMC_best), \n",
    "                                      ('gbc', GBC_best), \n",
    "                                      ('xgb', XGBC_best)\n",
    "                                      ], \n",
    "                          voting='soft', n_jobs=-1, verbose=10)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = None, stratify=y)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsVC = GridSearchCV(estimator=VC, param_grid=param_grid, cv=KFOLD_TIME, n_jobs = -1, verbose=10)\n",
    "\n",
    "    gsVC = gsVC.fit(X_train,y_train)\n",
    "    score = gsVC.score(X_test, y_test)\n",
    "    y_test_predict = gsVC.predict_proba(X_test)\n",
    "        \n",
    "    model_metrics[i] = np.array(calc_metrics(y_test, y_test_predict[:, 1]))\n",
    "    if i == 0 :\n",
    "        model_metrics[\"mean\"] = model_metrics[i]\n",
    "    else : \n",
    "        for j in range(5) :\n",
    "            model_metrics[\"mean\"][j] = (model_metrics[\"mean\"][j] * i + model_metrics[i][j]) / (i+1)\n",
    "\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsVC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsVC.best_params_))\n",
    "    logger.warning('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsVC.best_estimator_))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 score set ==> \\n{}'.format(model_metrics[i]))\n",
    "    \n",
    "    return score, gsVC.best_params_, gsVC.best_estimator_\n",
    "\n",
    "def classify(npz_path, param_grid) :\n",
    "    logger.debug(\"Dataset : {}\".format(npz_path))\n",
    "    if npz_path[4:4+7] == 'STRUCT_' : \n",
    "        mydata = np.load(npz_path)\n",
    "        XP = mydata['XP'] \n",
    "        XR = mydata['XR']\n",
    "        Y = mydata['Y']        \n",
    "        combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_struct_feature_names + r_struct_feature_names + ['target'])\n",
    "        \n",
    "    else :\n",
    "        mydata = np.load(npz_path)\n",
    "        XP = mydata['XP']\n",
    "        XR = mydata['XR']\n",
    "        Y = mydata['Y']\n",
    "        combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_feature_names + xgb_r_feature_names + ['target'])\n",
    "\n",
    "    features = list(combined_pd.columns[:-1])\n",
    "    X = combined_pd[features]\n",
    "    y = combined_pd['target']\n",
    "\n",
    "    return Voting_Classifying(X, y, param_grid)\n",
    "    #return RF_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "    #return XGB_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "    #return LGBM_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "\n",
    "def classify_and_print_NPInter(dataset):\n",
    "    logger.debug(\"=======================================================\")\n",
    "    best_score, best_params, best_model = classify(dataset[\"NPInter\"], PARAM_GRID[\"NPInter\"])\n",
    "    logger.warning(\"K_fold with {0} epoch : {1}\".format(KFOLD_TIME, best_score))\n",
    "    save_best_output(dataset[\"NPInter\"], best_score, best_params, str(best_model).replace('\\n', ''))\n",
    "    \n",
    "def classify_and_print_RPI(size, dataset):\n",
    "    logger.debug(\"=======================================================\")\n",
    "    best_score, best_params, best_model = classify(dataset[\"RPI\"][size], PARAM_GRID[\"RPI\"][size])\n",
    "    logger.warning(\"K_fold with {0} epoch : {1}\".format(KFOLD_TIME, best_score))\n",
    "\n",
    "    save_best_output(dataset[\"RPI\"][size], best_score, best_params, str(best_model).replace('\\n', ''))\n",
    "\n",
    "i=0\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(10) :\n",
    "        logger.debug('{}th try'.format(i+1))\n",
    "        dataset = NPZ_PATH_STRUCT\n",
    "        logger.debug(\"Classification is about to start ... \")\n",
    "        #classify_and_print_RPI(369, dataset)\n",
    "        classify_and_print_RPI(488, dataset)\n",
    "        classify_and_print_RPI(1807, dataset)\n",
    "        #classify_and_print_RPI(2241, dataset)\n",
    "        #classify_and_print_NPInter(dataset)\n",
    "    print('model_metrics : {}'.format(model_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
