{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification is about to start ... \n",
      "=======================================================\n",
      "Dataset : npz/STRUCT_RPI369.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npz/STRUCT_RPI369.npz\n",
      "woojung1\n",
      "XP : [[-1.73591588  0.67360464  0.21132711 ...  1.40223943 -0.25241339\n",
      "   0.83839785]\n",
      " [-0.46954611  0.67360464  0.61063615 ...  0.30902714 -0.15889085\n",
      "   0.83839785]\n",
      " [-0.27347588  0.67360464  1.39649332 ... -0.82821861 -0.76173988\n",
      "   0.83839785]\n",
      " ...\n",
      " [-2.25920917  0.67360464 -0.4680458  ... -0.25484025 -0.77220179\n",
      "  -0.91393224]\n",
      " [-1.45833137  0.67360464 -1.00031303 ... -0.52174822  0.35668608\n",
      "  -0.78557544]\n",
      " [ 0.93661771 -3.14583706 -1.01560008 ... -2.89110338  0.2402907\n",
      "   0.83839785]] - len : 738 - XP[0] : 438\n",
      "XR : [[-0.96906667 -0.85382913  0.94600668 ...  1.37358442  0.37164361\n",
      "   0.50008494]\n",
      " [-0.27381136  1.46852911 -0.7660762  ... -0.63274384 -0.53793563\n",
      "   0.50008494]\n",
      " [-0.27381136  1.46852911 -0.7660762  ... -0.63274384 -0.53793563\n",
      "   0.50008494]\n",
      " ...\n",
      " [ 0.25785447  1.46852911 -1.90746479 ... -0.63274384 -0.08314601\n",
      "   0.50008494]\n",
      " [-0.22950587  0.294448    0.11374417 ... -0.35185789  0.08057825\n",
      "   0.50008494]\n",
      " [-0.53964427 -1.04735899 -0.55206584 ... -0.63274384 -0.90176733\n",
      "   0.50008494]] - len : 738 - XR[0] : 370\n",
      "Y : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] - len : 738 - \n",
      "column len : 809\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   15.1s remaining:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   15.1s remaining:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.2s finished\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.581\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'gbc__learning_rate': 0.05, 'gbc__max_depth': 6, 'gbc__min_samples_leaf': 3, 'gbc__min_samples_split': 2, 'gbc__n_estimators': 100, 'rfc__max_depth': 6, 'rfc__max_leaf_nodes': 10, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 30, 'svc__C': 0.1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 2, 'xgb__C': 0.1, 'xgb__gamma': 0.1, 'xgb__kernel': 'rbf', 'xgb__learning_rate': 0.1, 'xgb__max_depth': 100, 'xgb__n_estimators': 100, 'xgb__num_iterations': 1000, 'xgb__random_state': 2}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.615\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "VotingClassifier(estimators=[('rfc',\n",
      "                              RandomForestClassifier(max_depth=6,\n",
      "                                                     max_leaf_nodes=10,\n",
      "                                                     min_samples_leaf=8,\n",
      "                                                     min_samples_split=20,\n",
      "                                                     n_estimators=30,\n",
      "                                                     random_state=2)),\n",
      "                             ('svc',\n",
      "                              SVC(C=0.1, gamma=0.1, probability=True,\n",
      "                                  random_state=2)),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(learning_rate=0.05,\n",
      "                                                         max_depth=6,\n",
      "                                                         min_samples_leaf=3,\n",
      "                                                         random_state=2)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(C=0.1, gamma=0.1, kernel='rbf',\n",
      "                                            max_depth=100, num_iterations=1000,\n",
      "                                            probability=True,\n",
      "                                            random_state=2))],\n",
      "                 n_jobs=-1, verbose=10, voting='soft')\n",
      "K_fold with 5 epoch : 0.6148648648648649\n",
      "[save_best_output]best_score_so_far : 0.6418918918918919\n",
      "=======================================================\n",
      "Dataset : npz/STRUCT_RPI488.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npz/STRUCT_RPI488.npz\n",
      "woojung1\n",
      "XP : [[ 0.71339464 -1.26409292 -1.6786168  ... -1.54247191  0.59258984\n",
      "   0.62052579]\n",
      " [ 0.71339464 -1.02663474 -0.72916221 ... -0.52407744 -0.80381441\n",
      "   0.62052579]\n",
      " [ 0.71339464  0.46584686  0.74076938 ... -0.41000695 -0.51318394\n",
      "   0.62052579]\n",
      " ...\n",
      " [-0.9498774   1.15894977  0.96584581 ...  1.43085473  1.74113975\n",
      "  -1.42232514]\n",
      " [-0.45089579  1.15894977 -0.19816433 ... -0.38443943  0.17633685\n",
      "  -1.67768151]\n",
      " [-0.37812763  1.15894977  0.09937759 ... -0.56011306 -0.82600233\n",
      "   0.62052579]] - len : 488 - XP[0] : 438\n",
      "XR : [[ 0.66868093  0.12437586 -0.07624149 ... -0.38532828 -0.05625958\n",
      "   0.        ]\n",
      " [ 0.66868093  0.12437586 -0.07624149 ... -0.38532828 -0.05625958\n",
      "   0.        ]\n",
      " [ 0.66868093  0.12437586 -0.07624149 ... -0.38532828 -0.05625958\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.16327481  1.47043825 -0.09310155 ... -0.89434803 -1.52522332\n",
      "   0.        ]\n",
      " [-0.16327481  1.47043825 -0.09310155 ... -0.89434803 -1.52522332\n",
      "   0.        ]\n",
      " [-0.16327481  1.47043825 -0.09310155 ... -0.89434803 -1.52522332\n",
      "   0.        ]] - len : 488 - XR[0] : 370\n",
      "Y : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0] - len : 488 - \n",
      "column len : 809\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.6s remaining:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    7.6s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.2s finished\n",
      "GridSearchCV를 이용한 최적 매개변수 점수 ==> 0.879\n",
      "GridSearchCV를 이용한 최적 매개변수 ==> {'gbc__learning_rate': 0.05, 'gbc__max_depth': 6, 'gbc__min_samples_leaf': 3, 'gbc__min_samples_split': 2, 'gbc__n_estimators': 100, 'rfc__max_depth': 6, 'rfc__max_leaf_nodes': 10, 'rfc__min_samples_leaf': 8, 'rfc__min_samples_split': 20, 'rfc__n_estimators': 30, 'svc__C': 0.1, 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 2, 'xgb__C': 0.1, 'xgb__gamma': 0.1, 'xgb__kernel': 'rbf', 'xgb__learning_rate': 0.1, 'xgb__max_depth': 100, 'xgb__n_estimators': 100, 'xgb__num_iterations': 1000, 'xgb__random_state': 2}\n",
      "GridSearchCV를 이용한 test점수 ==> 0.847\n",
      "GridSearchCV를 이용한 최고 성능 모델 ==> \n",
      "VotingClassifier(estimators=[('rfc',\n",
      "                              RandomForestClassifier(max_depth=6,\n",
      "                                                     max_leaf_nodes=10,\n",
      "                                                     min_samples_leaf=8,\n",
      "                                                     min_samples_split=20,\n",
      "                                                     n_estimators=30,\n",
      "                                                     random_state=2)),\n",
      "                             ('svc',\n",
      "                              SVC(C=0.1, gamma=0.1, probability=True,\n",
      "                                  random_state=2)),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(learning_rate=0.05,\n",
      "                                                         max_depth=6,\n",
      "                                                         min_samples_leaf=3,\n",
      "                                                         random_state=2)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(C=0.1, gamma=0.1, kernel='rbf',\n",
      "                                            max_depth=100, num_iterations=1000,\n",
      "                                            probability=True,\n",
      "                                            random_state=2))],\n",
      "                 n_jobs=-1, verbose=10, voting='soft')\n",
      "K_fold with 5 epoch : 0.8469387755102041\n",
      "[save_best_output]best_score_so_far : 0.8979591836734694\n",
      "=======================================================\n",
      "Dataset : npz/STRUCT_RPI1807.npz\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npz/STRUCT_RPI1807.npz\n",
      "woojung1\n",
      "XP : [[-2.73680058  1.41647683  2.03488036 ... -1.15545298 -0.34779534\n",
      "  -1.30616615]\n",
      " [ 0.54913701 -0.33529941  1.73360408 ...  0.57348506  1.38076632\n",
      "   0.81411205]\n",
      " [ 0.54913701 -0.43133978  1.41151595 ...  1.40941029  0.95949737\n",
      "   0.81411205]\n",
      " ...\n",
      " [-2.90109746  1.41647683  0.22345671 ... -0.57185125 -0.95779159\n",
      "   0.81411205]\n",
      " [-2.22470641  1.41647683  1.43770773 ...  0.65503874  0.95949737\n",
      "   0.56870948]\n",
      " [-1.60557617  1.41647683  2.17193638 ...  1.89111742 -0.90027492\n",
      "  -0.54831571]] - len : 3237 - XP[0] : 438\n",
      "XR : [[-0.52283851  3.21696477  2.09164634 ... -1.7878371  -1.08112618\n",
      "  -3.21277869]\n",
      " [ 2.18050264  2.11505996 -1.04926182 ...  1.04120441 -1.471097\n",
      "   0.19566804]\n",
      " [ 2.18050264  2.11505996 -1.04926182 ...  1.04120441 -1.471097\n",
      "   0.19566804]\n",
      " ...\n",
      " [-3.7203388   3.21696477 -5.81128388 ... -1.7878371  -2.61411493\n",
      "  -4.70152554]\n",
      " [-3.7203388   3.21696477 -5.81128388 ... -1.7878371  -2.61411493\n",
      "  -4.70152554]\n",
      " [-3.7203388   3.21696477 -5.81128388 ... -1.7878371  -2.61411493\n",
      "  -4.70152554]] - len : 3237 - XR[0] : 370\n",
      "Y : [1 1 1 ... 0 0 0] - len : 3237 - \n",
      "column len : 809\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.3min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  1.3min remaining:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "from hyperparams import *\n",
    "from rawdata_preprocessing import *\n",
    "from features import *\n",
    "#from RandomForestClassifier import RF_Classifying\n",
    "#from SVMClassifier import SVM_Classifying\n",
    "\n",
    "import Bio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, roc_curve\n",
    "import math\n",
    "\n",
    "#from warnings import filterwarnings\n",
    "#filterwarnings('ignore')\n",
    "\n",
    "from Logger import *\n",
    "from save_best_output import save_best_output\n",
    "\n",
    "model_metrics = {}\n",
    "\n",
    "def calc_metrics(y_label, y_proba):\n",
    "    con_matrix = confusion_matrix(y_label, [1 if x >= 0.5 else 0 for x in y_proba])\n",
    "    TN = float(con_matrix[0][0])\n",
    "    FP = float(con_matrix[0][1])\n",
    "    FN = float(con_matrix[1][0])\n",
    "    TP = float(con_matrix[1][1])\n",
    "    P = TP + FN\n",
    "    N = TN + FP\n",
    "    Sn = TP / P if P > 0 else 0\n",
    "    Sp = TN / N if N > 0 else 0\n",
    "    Acc = (TP + TN) / (P + N) if (P + N) > 0 else 0\n",
    "    Pre = (TP) / (TP + FP) if (TP+FP) > 0 else 0\n",
    "    MCC = 0\n",
    "    tmp = math.sqrt((TP + FP) * (TP + FN)) * math.sqrt((TN + FP) * (TN + FN))\n",
    "    if tmp != 0:\n",
    "        MCC = (TP * TN - FP * FN) / tmp\n",
    "    fpr, tpr, thresholds = roc_curve(y_label, y_proba)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    return Acc, Sn, Sp, Pre, MCC, AUC\n",
    "\n",
    "def Voting_Classifying(X, y, KFOLD_TIME) :\n",
    "    #GBC_best = GBC_Classifying(X, y, KFOLD_TIME)\n",
    "    #RFC_best = RF_Classifying(X, y, KFOLD_TIME)\n",
    "    #SVMC_best = SVM_Classifying(X, y, KFOLD_TIME)\n",
    "    #XGBC_best = XGB_Classifying(X, y, KFOLD_TIME)\n",
    "    RFC_best = RandomForestClassifier(random_state=2)\n",
    "    SVMC_best = SVC(probability=True, random_state=2)\n",
    "    GBC_best = GradientBoostingClassifier(random_state=2)\n",
    "    XGBC_best = XGBClassifier(probability=True, random_state=2)\n",
    "    ABC_best = AdaBoostClassifier(random_state = 2)\n",
    "    BC_best = BaggingClassifier(random_state = 2)\n",
    "    LGBM_best = LGBMClassifier(random_state = 2)\n",
    "    \n",
    "    VC = VotingClassifier(estimators=[\n",
    "        #('ada', ABC_best), \n",
    "        #                              ('bc', BC_best),\n",
    "        #                              ('lgbm', LGBM_best),\n",
    "                                      ('rfc', RFC_best), \n",
    "                                      ('svc', SVMC_best), \n",
    "                                      ('gbc', GBC_best), \n",
    "                                      ('xgb', XGBC_best)\n",
    "                                      ], \n",
    "                          voting='soft', n_jobs=-1, verbose=10)\n",
    "    param_range = [0.1, 1.0]\n",
    "    param_grid = {\n",
    "        'gbc__n_estimators' : [100], 'gbc__max_depth' : [6], 'gbc__min_samples_leaf': [3], 'gbc__min_samples_split' : [2], 'gbc__learning_rate' : [0.05],\n",
    "        'svc__kernel' : ['rbf'], 'svc__C' : [0.1], 'svc__gamma': [0.1], 'svc__random_state' : [2],\n",
    "        'xgb__kernel' : ['rbf'], 'xgb__C' : [0.1], 'xgb__num_iterations': [1000], 'xgb__gamma':[0.1], 'xgb__random_state' : [2], 'xgb__learning_rate' : [0.1], 'xgb__n_estimators' : [100], 'xgb__max_depth' : [100],\n",
    "        'rfc__n_estimators' : [30],'rfc__max_depth' : [6],'rfc__min_samples_leaf' : [8],'rfc__min_samples_split' : [20], 'rfc__max_leaf_nodes' : [10],\n",
    "        #'ada__base_estimator' : [RFC_best, SVMC_best], 'ada__n_estimators' : [10], 'ada__learning_rate' : [0.01],\n",
    "        #'bc__base_estimator' : [SVMC_best, GBC_best, XGBC_best, ABC_best], 'bc__n_estimators' : [10],\n",
    "        #'lgbm__n_estimators' : [10], 'lgbm__min_samples_leaf' : [3], 'lgbm__min_samples_split' : [2], 'lgbm__learning_rate' : [0.01]\n",
    "    }\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsVC = GridSearchCV(estimator=VC, param_grid=param_grid, cv=KFOLD_TIME, n_jobs = -1, verbose=10)\n",
    "\n",
    "    gsVC = gsVC.fit(X_train,y_train)\n",
    "    score = gsVC.score(X_test, y_test)\n",
    "    y_test_predict = gsVC.predict_proba(X_test)\n",
    "    #logger.debug('len : {0} - y_test : {1} - y_test[:, 1] : '.format(len(y_test), y_test))\n",
    "    #logger.debug('len : {0} - y_test_predict : {1} - y_test_predict[:, 1] : {2}'.format(len(y_test_predict), y_test_predict, y_test_predict[:, 1]))\n",
    "    model_metrics['Voting-Classifier'] = np.array(calc_metrics(y_test, y_test_predict[:, 1]))\n",
    "\n",
    "    \n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsVC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsVC.best_params_))\n",
    "    logger.warning('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsVC.best_estimator_))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 score set ==> \\n{}'.format(model_metrics))\n",
    "    \n",
    "    return score, gsVC.best_params_, gsVC.best_estimator_, model_metrics['Voting-Classifier']\n",
    "\n",
    "\n",
    "def Bagging_Classifying(X, y, KFOLD_TIME) :\n",
    "    BC = BaggingClassifier()\n",
    "    \n",
    "\"\"\"\n",
    "def GBC_Classifying(X, y, KFOLD_TIME) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"GBC_Classifying ... \")\n",
    "    gbrt = GradientBoostingClassifier(random_state = 0)\n",
    "    '''\n",
    "    param_grid = {\n",
    "        'n_estimators' : [100, 200], \n",
    "        'max_depth' : [6,8,10,12], \n",
    "        'min_samples_leaf': [3,5,7,10], \n",
    "        'min_samples_split' : [2,3,5,10], \n",
    "        'learning_rate' : [0.05, 0.1, 0.2]\n",
    "    }\n",
    "    '''\n",
    "    param_grid = {'n_estimators' : [100], 'max_depth' : [6], 'min_samples_leaf': [3], 'min_samples_split' : [2], 'learning_rate' : [0.05]}\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsGBRT = GridSearchCV(gbrt, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=6, verbose=2)\n",
    "    \n",
    "    '''\n",
    "    gsGBRT.fit(X_train, y_train)\n",
    "    score = gsGBRT.score(X_test, y_test)\n",
    "    print('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsGBRT.best_score_))\n",
    "    print('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsGBRT.best_params_))\n",
    "    print('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    print('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsGBRT.best_estimator_))\n",
    "    '''\n",
    "    return score, gsGBRT.best_params_, gsGBRT.best_estimator_\n",
    "\n",
    "def SVM_Classifying(X, y, KFOLD_TIME) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"SVM_Classifying ... \")\n",
    "    SVMC = SVC(probability=True)\n",
    "    param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    #param_range = [0.1, 1.0]\n",
    "    '''\n",
    "    param_grid = [\n",
    "        {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['poly'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['linear'], 'C' : param_range, 'random_state' : [2] },\n",
    "        {'kernel' = ['sigmoid'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] }\n",
    "    ]\n",
    "    '''\n",
    "    param_grid = [\n",
    "        {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2] }  \n",
    "    ]\n",
    "\n",
    "    #['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsSVMC = GridSearchCV(SVMC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=6, verbose=2)\n",
    "\n",
    "\n",
    "    '''\n",
    "    gsSVMC.fit(X, y)\n",
    "    score = gsSVMC.score(X_test, y_test)\n",
    "\n",
    "    SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "    print(\"best score : {}\".format(gsSVMC.best_score_))\n",
    "    print(\"best parameters : {}\".format(gsSVMC.best_params_))\n",
    "    print(\"train set score : {}\".format(gsSVMC.score(X, y)))\n",
    "    '''\n",
    "    return score, gsSVMC.best_params_, gsSVMC.best_estimator_\n",
    "\"\"\"\n",
    "def XGB_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"XGB_Classifying ...\")\n",
    "    XGBC = XGBClassifier(probability=True)\n",
    "    param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    '''\n",
    "    param_grid = {'kernel' : ['rbf'], 'C' : param_range, 'gamma': param_range, 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01, 0.05, 0.1, 0.15, 0.2], \n",
    "                  'n_estimators' : [100, 200, 400, 600], \n",
    "                  'max_depth' : [4,6,8,10,12] }\n",
    "    \n",
    "    param_grid = {'kernel' : ['rbf'], 'C' : param_range, 'gamma':[0.1], 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01], \n",
    "                  'n_estimators' : [100], \n",
    "                  'max_depth' : [4]}\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsXGBC = GridSearchCV(XGBC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsXGBC.fit(X_train, y_train)\n",
    "    score = gsXGBC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsXGBC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsXGBC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsXGBC.best_estimator_))\n",
    "    \n",
    "    return score, gsXGBC.best_params_, gsXGBC.best_estimator_\n",
    "\n",
    "def LGBM_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    print(\"=======================================================\")\n",
    "    print(\"LGBM_Classifying ...\")\n",
    "    LGBC = LGBMClassifier(random_state = 2)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    gsLGBM = GridSearchCV(LGBC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsLGBM.fit(X_train, y_train)\n",
    "    score = gsLGBM.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsLGBM.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsLGBM.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsLGBM.best_estimator_))\n",
    "    \n",
    "    return score, gsLGBM.best_params_, gsLGBM.best_estimator_\n",
    "\n",
    "def RF_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"RF_Classifying ... \")\n",
    "    RFC = RandomForestClassifier(random_state=2)\n",
    "\n",
    "    \n",
    "    param_grid = {'n_estimators' : [10],'max_depth' : [6],'min_samples_leaf' : [8],'min_samples_split' : [8], 'max_leaf_nodes' : [10]}\n",
    "\n",
    "    kfold = KFold(n_splits=KFOLD_TIME, shuffle=True, random_state=11)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    \n",
    "    gsRFC = GridSearchCV(RFC, param_grid = param_grid, cv=kfold,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=10)\n",
    "    \n",
    "    gsRFC.fit(X_train, y_train)\n",
    "    # X_train, y_train 을 0.8:0.2 이런식으로 나눠서 cv 시킨다는 뜻인듯 ?\n",
    "    \n",
    "    score = gsRFC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsRFC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsRFC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsRFC.best_estimator_))\n",
    "    \n",
    "    #return gsRFC\n",
    "    return score, gsRFC.best_params_, gsRFC.best_estimator_\n",
    "\n",
    "def LR_Classifying(X, y, KFOLD_TIME, param_grid) :\n",
    "    logger.debug(\"=======================================================\")\n",
    "    logger.debug(\"LogisticRegressionCV_Classifying ... \")\n",
    "    \n",
    "    LRC = LogisticRegressionCV(random_state = 2)\n",
    "    param_range = [0.01 ,0.1, 1, 10, 100]\n",
    "    param_grid = {'C' : param_range, 'gamma':[0.1], 'random_state' : [2],\n",
    "                  'learning_rate' : [0.01], \n",
    "                  'n_estimators' : [100], \n",
    "                  'max_depth' : [4]}\n",
    "    gsLRC = GridSearchCV(LRC, param_grid = param_grid, cv=KFOLD_TIME,\n",
    "                         scoring=\"accuracy\", n_jobs=-1, verbose=2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    gsLRC.fit(X_train, y_train)\n",
    "    \n",
    "    score = gsLRC.score(X_test, y_test)\n",
    "    \n",
    "    \n",
    "    score = gsLRC.score(X_test, y_test)\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 점수 ==> {:.3f}'.format(gsLRC.best_score_))\n",
    "    logger.debug('GridSearchCV를 이용한 최적 매개변수 ==> {}'.format(gsLRC.best_params_))\n",
    "    logger.debug('GridSearchCV를 이용한 test점수 ==> {:.3f}'.format(score))\n",
    "    logger.debug('GridSearchCV를 이용한 최고 성능 모델 ==> \\n{}'.format(gsLRC.best_estimator_))\n",
    "    return score, gsLRC.best_params_, gsLRC.best_estimator_\n",
    "\n",
    "KFOLD_TIME = 5\n",
    "cv=KFold(n_splits=3,random_state=5,shuffle=True)\n",
    "'''\n",
    "p_feature_names = ['A', 'AA', 'AAA', 'AAB', 'AAC', 'AAD', 'AAE', 'AAF', 'AAG', 'AB', 'ABA', 'ABB', 'ABC', 'ABD', 'ABE', 'ABF', 'ABG', 'AC', 'ACA', 'ACB', 'ACC', 'ACD', 'ACE', 'ACF', 'ACG', 'AD', 'ADA', 'ADB', 'ADC', 'ADD', 'ADE', 'ADF', 'ADG', 'AE', 'AEA', 'AEB', 'AEC', 'AED', 'AEE', 'AEF', 'AEG', 'AF', 'AFA', 'AFB', 'AFC', 'AFD', 'AFE', 'AFF', 'AFG', 'AG', 'AGA', 'AGB', 'AGC', 'AGD', 'AGE', 'AGF', 'AGG', 'B', 'BA', 'BAA', 'BAB', 'BAC', 'BAD', 'BAE', 'BAF', 'BAG', 'BB', 'BBA', 'BBB', 'BBC', 'BBD', 'BBE', 'BBF', 'BBG', 'BC', 'BCA', 'BCB', 'BCC', 'BCD', 'BCE', 'BCF', 'BCG', 'BD', 'BDA', 'BDB', 'BDC', 'BDD', 'BDE', 'BDF', 'BDG', 'BE', 'BEA', 'BEB', 'BEC', 'BED', 'BEE', 'BEF', 'BEG', 'BF', 'BFA', 'BFB', 'BFC', 'BFD', 'BFE', 'BFF', 'BFG', 'BG', 'BGA', 'BGB', 'BGC', 'BGD', 'BGE', 'BGF', 'BGG', 'C', 'CA', 'CAA', 'CAB', 'CAC', 'CAD', 'CAE', 'CAF', 'CAG', 'CB', 'CBA', 'CBB', 'CBC', 'CBD', 'CBE', 'CBF', 'CBG', 'CC', 'CCA', 'CCB', 'CCC', 'CCD', 'CCE', 'CCF', 'CCG', 'CD', 'CDA', 'CDB', 'CDC', 'CDD', 'CDE', 'CDF', 'CDG', 'CE', 'CEA', 'CEB', 'CEC', 'CED', 'CEE', 'CEF', 'CEG', 'CF', 'CFA', 'CFB', 'CFC', 'CFD', 'CFE', 'CFF', 'CFG', 'CG', 'CGA', 'CGB', 'CGC', 'CGD', 'CGE', 'CGF', 'CGG', 'D', 'DA', 'DAA', 'DAB', 'DAC', 'DAD', 'DAE', 'DAF', 'DAG', 'DB', 'DBA', 'DBB', 'DBC', 'DBD', 'DBE', 'DBF', 'DBG', 'DC', 'DCA', 'DCB', 'DCC', 'DCD', 'DCE', 'DCF', 'DCG', 'DD', 'DDA', 'DDB', 'DDC', 'DDD', 'DDE', 'DDF', 'DDG', 'DE', 'DEA', 'DEB', 'DEC', 'DED', 'DEE', 'DEF', 'DEG', 'DF', 'DFA', 'DFB', 'DFC', 'DFD', 'DFE', 'DFF', 'DFG', 'DG', 'DGA', 'DGB', 'DGC', 'DGD', 'DGE', 'DGF', 'DGG', 'E', 'EA', 'EAA', 'EAB', 'EAC', 'EAD', 'EAE', 'EAF', 'EAG', 'EB', 'EBA', 'EBB', 'EBC', 'EBD', 'EBE', 'EBF', 'EBG', 'EC', 'ECA', 'ECB', 'ECC', 'ECD', 'ECE', 'ECF', 'ECG', 'ED', 'EDA', 'EDB', 'EDC', 'EDD', 'EDE', 'EDF', 'EDG', 'EE', 'EEA', 'EEB', 'EEC', 'EED', 'EEE', 'EEF', 'EEG', 'EF', 'EFA', 'EFB', 'EFC', 'EFD', 'EFE', 'EFF', 'EFG', 'EG', 'EGA', 'EGB', 'EGC', 'EGD', 'EGE', 'EGF', 'EGG', 'F', 'FA', 'FAA', 'FAB', 'FAC', 'FAD', 'FAE', 'FAF', 'FAG', 'FB', 'FBA', 'FBB', 'FBC', 'FBD', 'FBE', 'FBF', 'FBG', 'FC', 'FCA', 'FCB', 'FCC', 'FCD', 'FCE', 'FCF', 'FCG', 'FD', 'FDA', 'FDB', 'FDC', 'FDD', 'FDE', 'FDF', 'FDG', 'FE', 'FEA', 'FEB', 'FEC', 'FED', 'FEE', 'FEF', 'FEG', 'FF', 'FFA', 'FFB', 'FFC', 'FFD', 'FFE', 'FFF', 'FFG', 'FG', 'FGA', 'FGB', 'FGC', 'FGD', 'FGE', 'FGF', 'FGG', 'G', 'GA', 'GAA', 'GAB', 'GAC', 'GAD', 'GAE', 'GAF', 'GAG', 'GB', 'GBA', 'GBB', 'GBC', 'GBD', 'GBE', 'GBF', 'GBG', 'GC', 'GCA', 'GCB', 'GCC', 'GCD', 'GCE', 'GCF', 'GCG', 'GD', 'GDA', 'GDB', 'GDC', 'GDD', 'GDE', 'GDF', 'GDG', 'GE', 'GEA', 'GEB', 'GEC', 'GED', 'GEE', 'GEF', 'GEG', 'GF', 'GFA', 'GFB', 'GFC', 'GFD', 'GFE', 'GFF', 'GFG', 'GG', 'GGA', 'GGB', 'GGC', 'GGD', 'GGE', 'GGF', 'GGG']\n",
    "r_feature_names = ['A', 'AA', 'AAA', 'AAAA', 'AAAC', 'AAAG', 'AAAU', 'AAC', 'AACA', 'AACC', 'AACG', 'AACU', 'AAG', 'AAGA', 'AAGC', 'AAGG', 'AAGU', 'AAU', 'AAUA', 'AAUC', 'AAUG', 'AAUU', 'AC', 'ACA', 'ACAA', 'ACAC', 'ACAG', 'ACAU', 'ACC', 'ACCA', 'ACCC', 'ACCG', 'ACCU', 'ACG', 'ACGA', 'ACGC', 'ACGG', 'ACGU', 'ACU', 'ACUA', 'ACUC', 'ACUG', 'ACUU', 'AG', 'AGA', 'AGAA', 'AGAC', 'AGAG', 'AGAU', 'AGC', 'AGCA', 'AGCC', 'AGCG', 'AGCU', 'AGG', 'AGGA', 'AGGC', 'AGGG', 'AGGU', 'AGU', 'AGUA', 'AGUC', 'AGUG', 'AGUU', 'AU', 'AUA', 'AUAA', 'AUAC', 'AUAG', 'AUAU', 'AUC', 'AUCA', 'AUCC', 'AUCG', 'AUCU', 'AUG', 'AUGA', 'AUGC', 'AUGG', 'AUGU', 'AUU', 'AUUA', 'AUUC', 'AUUG', 'AUUU', 'C', 'CA', 'CAA', 'CAAA', 'CAAC', 'CAAG', 'CAAU', 'CAC', 'CACA', 'CACC', 'CACG', 'CACU', 'CAG', 'CAGA', 'CAGC', 'CAGG', 'CAGU', 'CAU', 'CAUA', 'CAUC', 'CAUG', 'CAUU', 'CC', 'CCA', 'CCAA', 'CCAC', 'CCAG', 'CCAU', 'CCC', 'CCCA', 'CCCC', 'CCCG', 'CCCU', 'CCG', 'CCGA', 'CCGC', 'CCGG', 'CCGU', 'CCU', 'CCUA', 'CCUC', 'CCUG', 'CCUU', 'CG', 'CGA', 'CGAA', 'CGAC', 'CGAG', 'CGAU', 'CGC', 'CGCA', 'CGCC', 'CGCG', 'CGCU', 'CGG', 'CGGA', 'CGGC', 'CGGG', 'CGGU', 'CGU', 'CGUA', 'CGUC', 'CGUG', 'CGUU', 'CU', 'CUA', 'CUAA', 'CUAC', 'CUAG', 'CUAU', 'CUC', 'CUCA', 'CUCC', 'CUCG', 'CUCU', 'CUG', 'CUGA', 'CUGC', 'CUGG', 'CUGU', 'CUU', 'CUUA', 'CUUC', 'CUUG', 'CUUU', 'G', 'GA', 'GAA', 'GAAA', 'GAAC', 'GAAG', 'GAAU', 'GAC', 'GACA', 'GACC', 'GACG', 'GACU', 'GAG', 'GAGA', 'GAGC', 'GAGG', 'GAGU', 'GAU', 'GAUA', 'GAUC', 'GAUG', 'GAUU', 'GC', 'GCA', 'GCAA', 'GCAC', 'GCAG', 'GCAU', 'GCC', 'GCCA', 'GCCC', 'GCCG', 'GCCU', 'GCG', 'GCGA', 'GCGC', 'GCGG', 'GCGU', 'GCU', 'GCUA', 'GCUC', 'GCUG', 'GCUU', 'GG', 'GGA', 'GGAA', 'GGAC', 'GGAG', 'GGAU', 'GGC', 'GGCA', 'GGCC', 'GGCG', 'GGCU', 'GGG', 'GGGA', 'GGGC', 'GGGG', 'GGGU', 'GGU', 'GGUA', 'GGUC', 'GGUG', 'GGUU', 'GU', 'GUA', 'GUAA', 'GUAC', 'GUAG', 'GUAU', 'GUC', 'GUCA', 'GUCC', 'GUCG', 'GUCU', 'GUG', 'GUGA', 'GUGC', 'GUGG', 'GUGU', 'GUU', 'GUUA', 'GUUC', 'GUUG', 'GUUU', 'U', 'UA', 'UAA', 'UAAA', 'UAAC', 'UAAG', 'UAAU', 'UAC', 'UACA', 'UACC', 'UACG', 'UACU', 'UAG', 'UAGA', 'UAGC', 'UAGG', 'UAGU', 'UAU', 'UAUA', 'UAUC', 'UAUG', 'UAUU', 'UC', 'UCA', 'UCAA', 'UCAC', 'UCAG', 'UCAU', 'UCC', 'UCCA', 'UCCC', 'UCCG', 'UCCU', 'UCG', 'UCGA', 'UCGC', 'UCGG', 'UCGU', 'UCU', 'UCUA', 'UCUC', 'UCUG', 'UCUU', 'UG', 'UGA', 'UGAA', 'UGAC', 'UGAG', 'UGAU', 'UGC', 'UGCA', 'UGCC', 'UGCG', 'UGCU', 'UGG', 'UGGA', 'UGGC', 'UGGG', 'UGGU', 'UGU', 'UGUA', 'UGUC', 'UGUG', 'UGUU', 'UU', 'UUA', 'UUAA', 'UUAC', 'UUAG', 'UUAU', 'UUC', 'UUCA', 'UUCC', 'UUCG', 'UUCU', 'UUG', 'UUGA', 'UUGC', 'UUGG', 'UUGU', 'UUU', 'UUUA', 'UUUC', 'UUUG', 'UUUU']\n",
    "xgb_r_feature_names = ['r_A', 'r_AA', 'r_AAA', 'r_AAAA', 'r_AAAC', 'r_AAAG', 'r_AAAU', 'r_AAC', 'r_AACA', 'r_AACC', 'r_AACG', 'r_AACU', 'r_AAG', 'r_AAGA', 'r_AAGC', 'r_AAGG', 'r_AAGU', 'r_AAU', 'r_AAUA', 'r_AAUC', 'r_AAUG', 'r_AAUU', 'r_AC', 'r_ACA', 'r_ACAA', 'r_ACAC', 'r_ACAG', 'r_ACAU', 'r_ACC', 'r_ACCA', 'r_ACCC', 'r_ACCG', 'r_ACCU', 'r_ACG', 'r_ACGA', 'r_ACGC', 'r_ACGG', 'r_ACGU', 'r_ACU', 'r_ACUA', 'r_ACUC', 'r_ACUG', 'r_ACUU', 'r_AG', 'r_AGA', 'r_AGAA', 'r_AGAC', 'r_AGAG', 'r_AGAU', 'r_AGC', 'r_AGCA', 'r_AGCC', 'r_AGCG', 'r_AGCU', 'r_AGG', 'r_AGGA', 'r_AGGC', 'r_AGGG', 'r_AGGU', 'r_AGU', 'r_AGUA', 'r_AGUC', 'r_AGUG', 'r_AGUU', 'r_AU', 'r_AUA', 'r_AUAA', 'r_AUAC', 'r_AUAG', 'r_AUAU', 'r_AUC', 'r_AUCA', 'r_AUCC', 'r_AUCG', 'r_AUCU', 'r_AUG', 'r_AUGA', 'r_AUGC', 'r_AUGG', 'r_AUGU', 'r_AUU', 'r_AUUA', 'r_AUUC', 'r_AUUG', 'r_AUUU', 'r_C', 'r_CA', 'r_CAA', 'r_CAAA', 'r_CAAC', 'r_CAAG', 'r_CAAU', 'r_CAC', 'r_CACA', 'r_CACC', 'r_CACG', 'r_CACU', 'r_CAG', 'r_CAGA', 'r_CAGC', 'r_CAGG', 'r_CAGU', 'r_CAU', 'r_CAUA', 'r_CAUC', 'r_CAUG', 'r_CAUU', 'r_CC', 'r_CCA', 'r_CCAA', 'r_CCAC', 'r_CCAG', 'r_CCAU', 'r_CCC', 'r_CCCA', 'r_CCCC', 'r_CCCG', 'r_CCCU', 'r_CCG', 'r_CCGA', 'r_CCGC', 'r_CCGG', 'r_CCGU', 'r_CCU', 'r_CCUA', 'r_CCUC', 'r_CCUG', 'r_CCUU', 'r_CG', 'r_CGA', 'r_CGAA', 'r_CGAC', 'r_CGAG', 'r_CGAU', 'r_CGC', 'r_CGCA', 'r_CGCC', 'r_CGCG', 'r_CGCU', 'r_CGG', 'r_CGGA', 'r_CGGC', 'r_CGGG', 'r_CGGU', 'r_CGU', 'r_CGUA', 'r_CGUC', 'r_CGUG', 'r_CGUU', 'r_CU', 'r_CUA', 'r_CUAA', 'r_CUAC', 'r_CUAG', 'r_CUAU', 'r_CUC', 'r_CUCA', 'r_CUCC', 'r_CUCG', 'r_CUCU', 'r_CUG', 'r_CUGA', 'r_CUGC', 'r_CUGG', 'r_CUGU', 'r_CUU', 'r_CUUA', 'r_CUUC', 'r_CUUG', 'r_CUUU', 'r_G', 'r_GA', 'r_GAA', 'r_GAAA', 'r_GAAC', 'r_GAAG', 'r_GAAU', 'r_GAC', 'r_GACA', 'r_GACC', 'r_GACG', 'r_GACU', 'r_GAG', 'r_GAGA', 'r_GAGC', 'r_GAGG', 'r_GAGU', 'r_GAU', 'r_GAUA', 'r_GAUC', 'r_GAUG', 'r_GAUU', 'r_GC', 'r_GCA', 'r_GCAA', 'r_GCAC', 'r_GCAG', 'r_GCAU', 'r_GCC', 'r_GCCA', 'r_GCCC', 'r_GCCG', 'r_GCCU', 'r_GCG', 'r_GCGA', 'r_GCGC', 'r_GCGG', 'r_GCGU', 'r_GCU', 'r_GCUA', 'r_GCUC', 'r_GCUG', 'r_GCUU', 'r_GG', 'r_GGA', 'r_GGAA', 'r_GGAC', 'r_GGAG', 'r_GGAU', 'r_GGC', 'r_GGCA', 'r_GGCC', 'r_GGCG', 'r_GGCU', 'r_GGG', 'r_GGGA', 'r_GGGC', 'r_GGGG', 'r_GGGU', 'r_GGU', 'r_GGUA', 'r_GGUC', 'r_GGUG', 'r_GGUU', 'r_GU', 'r_GUA', 'r_GUAA', 'r_GUAC', 'r_GUAG', 'r_GUAU', 'r_GUC', 'r_GUCA', 'r_GUCC', 'r_GUCG', 'r_GUCU', 'r_GUG', 'r_GUGA', 'r_GUGC', 'r_GUGG', 'r_GUGU', 'r_GUU', 'r_GUUA', 'r_GUUC', 'r_GUUG', 'r_GUUU', 'r_U', 'r_UA', 'r_UAA', 'r_UAAA', 'r_UAAC', 'r_UAAG', 'r_UAAU', 'r_UAC', 'r_UACA', 'r_UACC', 'r_UACG', 'r_UACU', 'r_UAG', 'r_UAGA', 'r_UAGC', 'r_UAGG', 'r_UAGU', 'r_UAU', 'r_UAUA', 'r_UAUC', 'r_UAUG', 'r_UAUU', 'r_UC', 'r_UCA', 'r_UCAA', 'r_UCAC', 'r_UCAG', 'r_UCAU', 'r_UCC', 'r_UCCA', 'r_UCCC', 'r_UCCG', 'r_UCCU', 'r_UCG', 'r_UCGA', 'r_UCGC', 'r_UCGG', 'r_UCGU', 'r_UCU', 'r_UCUA', 'r_UCUC', 'r_UCUG', 'r_UCUU', 'r_UG', 'r_UGA', 'r_UGAA', 'r_UGAC', 'r_UGAG', 'r_UGAU', 'r_UGC', 'r_UGCA', 'r_UGCC', 'r_UGCG', 'r_UGCU', 'r_UGG', 'r_UGGA', 'r_UGGC', 'r_UGGG', 'r_UGGU', 'r_UGU', 'r_UGUA', 'r_UGUC', 'r_UGUG', 'r_UGUU', 'r_UU', 'r_UUA', 'r_UUAA', 'r_UUAC', 'r_UUAG', 'r_UUAU', 'r_UUC', 'r_UUCA', 'r_UUCC', 'r_UUCG', 'r_UUCU', 'r_UUG', 'r_UUGA', 'r_UUGC', 'r_UUGG', 'r_UUGU', 'r_UUU', 'r_UUUA', 'r_UUUC', 'r_UUUG', 'r_UUUU']\n",
    "'''\n",
    "train_combined_arr = []\n",
    "val_combined_arr = []\n",
    "\n",
    "def classify(npz_path, param_grid) :\n",
    "    logger.debug(\"Dataset : {}\".format(npz_path))\n",
    "    if npz_path[4:4+7] == 'STRUCT_' : \n",
    "        print(npz_path)\n",
    "        print('woojung1')\n",
    "        mydata = np.load(npz_path)\n",
    "        XP = mydata['XP']\n",
    "        XR = mydata['XR']\n",
    "        Y = mydata['Y']\n",
    "        #print('XP : {0} - len : {1} - XP[0] : {2}'.format(XP, len(XP), len(XP[0])))\n",
    "        #print('XR : {0} - len : {1} - XR[0] : {2}'.format(XR, len(XP), len(XR[0])))\n",
    "        #print('Y : {0} - len : {1} - '.format(Y, len(Y)))\n",
    "        #print('column len : {}'.format(len(p_struct_feature_names + r_struct_feature_names + ['target'])))\n",
    "        \n",
    "        combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_struct_feature_names + r_struct_feature_names + ['target'])\n",
    "        \n",
    "    else :\n",
    "        print('woojung2')\n",
    "        mydata = np.load(npz_path)\n",
    "        XP = mydata['XP']\n",
    "        XR = mydata['XR']\n",
    "        Y = mydata['Y']\n",
    "        #print('XP : {0} - len : {1} - XP[0] : {2}'.format(XP, len(XP), len(XP[0])))\n",
    "        #print('XR : {0} - len : {1} - XR[0] : {2}'.format(XR, len(XP), len(XR[0])))\n",
    "        #print('Y : {0} - len : {1} - '.format(Y, len(Y)))\n",
    "\n",
    "        #combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_feature_names + r_feature_names + ['target'])\n",
    "        combined_pd = pd.DataFrame(data= np.c_[np.c_[XP, XR], Y], columns= p_feature_names + xgb_r_feature_names + ['target'])\n",
    "\n",
    "    features = list(combined_pd.columns[:-1])\n",
    "    X = combined_pd[features]\n",
    "    y = combined_pd['target']\n",
    "\n",
    "    return Voting_Classifying(X, y, KFOLD_TIME)\n",
    "    #return RF_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "    #return XGB_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "    #return LGBM_Classifying(X, y, KFOLD_TIME, param_grid)\n",
    "\n",
    "def classify_and_print_NPInter(dataset):\n",
    "    logger.debug(\"=======================================================\")\n",
    "    best_score, best_params, best_model, best_score_set = classify(dataset[\"NPInter\"], PARAM_GRID[\"NPInter\"][\"RFC\"])\n",
    "    logger.warning(\"K_fold with {0} epoch : {1}\".format(KFOLD_TIME, best_score))\n",
    "    save_best_output(dataset[\"NPInter\"], best_score, best_params, str(best_model).replace('\\n', ''))\n",
    "    \n",
    "def classify_and_print_RPI(size, dataset):\n",
    "    logger.debug(\"=======================================================\")\n",
    "    best_score, best_params, best_model, best_score_set = classify(dataset[\"RPI\"][size], PARAM_GRID[\"RPI\"][size][\"RFC\"])\n",
    "    logger.warning(\"K_fold with {0} epoch : {1}\".format(KFOLD_TIME, best_score))\n",
    "\n",
    "    save_best_output(dataset[\"RPI\"][size], best_score, best_params, str(best_model).replace('\\n', ''))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = NPZ_PATH_STRUCT\n",
    "    logger.debug(\"Classification is about to start ... \")\n",
    "    classify_and_print_RPI(369, dataset)\n",
    "    classify_and_print_RPI(488, dataset)\n",
    "    classify_and_print_RPI(1807, dataset)\n",
    "    classify_and_print_RPI(2241, dataset)\n",
    "    classify_and_print_NPInter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
